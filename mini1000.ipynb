{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini1000.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "231dbb8a2aee4141a03d9cd0ec0e44fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c31ae3495ee34d9a8b6c0487fda48308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51c8c5149b0c4794bf59d57c66836601",
              "IPY_MODEL_8155ec6a44144f4283b2d66abf9dc176"
            ]
          }
        },
        "c31ae3495ee34d9a8b6c0487fda48308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51c8c5149b0c4794bf59d57c66836601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6181f3ea4f3c46f4bfbe35381bc58e3e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f86226652444280b51b9d39fc2c1c84"
          }
        },
        "8155ec6a44144f4283b2d66abf9dc176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4eb178bd33f94bb18146db09d8dbb2f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:06&lt;00:00,  1.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30fc641b415b4854ac579aa8559cec8a"
          }
        },
        "6181f3ea4f3c46f4bfbe35381bc58e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f86226652444280b51b9d39fc2c1c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eb178bd33f94bb18146db09d8dbb2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30fc641b415b4854ac579aa8559cec8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bd0d401626449bab2a81f8812b8a3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08adf0b25eab4a8481e37ee86d2b401a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c624e6ae5a1c4563b9210fc9a1412442",
              "IPY_MODEL_5f830f0dcf8d44cc89ac64e8620654e7"
            ]
          }
        },
        "08adf0b25eab4a8481e37ee86d2b401a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c624e6ae5a1c4563b9210fc9a1412442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c02153c15c24b2aa9748faa4a89f8e1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1501,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1501,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80bf63542f2e4bda94bbc989a61e81b1"
          }
        },
        "5f830f0dcf8d44cc89ac64e8620654e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be4c623c62a14edc9521f9589669c097",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1501/1501 [00:02&lt;00:00, 662.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cab09b6dc994e43ad3897a9134b1861"
          }
        },
        "4c02153c15c24b2aa9748faa4a89f8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80bf63542f2e4bda94bbc989a61e81b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be4c623c62a14edc9521f9589669c097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cab09b6dc994e43ad3897a9134b1861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce0a49aaff0a49b5bd47cd5f208457df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4939ec4b9e6c47d88a36009137ad88b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36f0a3c2c40b463082ab3188ead18301",
              "IPY_MODEL_7be8e36f8b1b46ef9d76d058a8fdd4bd"
            ]
          }
        },
        "4939ec4b9e6c47d88a36009137ad88b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36f0a3c2c40b463082ab3188ead18301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d07d3a3a58a4ad69157e1d3ce6dbac3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68318b180c1c4c0abdc2b6c6e4f82efa"
          }
        },
        "7be8e36f8b1b46ef9d76d058a8fdd4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60bc3fbf379f4edea9e9ecf2ea908807",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1500/1500 [00:02&lt;00:00, 523.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad780477a9d64c65819e5b9b4083102a"
          }
        },
        "3d07d3a3a58a4ad69157e1d3ce6dbac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68318b180c1c4c0abdc2b6c6e4f82efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60bc3fbf379f4edea9e9ecf2ea908807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad780477a9d64c65819e5b9b4083102a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9b7e369f0a64b2fbfd759aabf9212f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_146e8c806ad54c00aa7ffe9dfad6e2d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc0a2366308b4aa28f849075977bbf0d",
              "IPY_MODEL_a39714d8df19455595371c6949648b4f"
            ]
          }
        },
        "146e8c806ad54c00aa7ffe9dfad6e2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc0a2366308b4aa28f849075977bbf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_921484e88f904e3bac3437a0704a6d7c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_596ebed2c31e4e35b99d6ce1177a273d"
          }
        },
        "a39714d8df19455595371c6949648b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10ceee2ce91c47c4a95a7f9649156dc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1500/1500 [03:51&lt;00:00,  6.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_215139b9aade42848d1c82628e350827"
          }
        },
        "921484e88f904e3bac3437a0704a6d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "596ebed2c31e4e35b99d6ce1177a273d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10ceee2ce91c47c4a95a7f9649156dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "215139b9aade42848d1c82628e350827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88a554c9ddf64ebfa1ca11348812eed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86428b7aabb44f4c971dbd6ee0df3248",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b772190c3ca4c1b925ff18571a1faa3",
              "IPY_MODEL_f00568ddfbd64c2dac86edc774272ba9"
            ]
          }
        },
        "86428b7aabb44f4c971dbd6ee0df3248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b772190c3ca4c1b925ff18571a1faa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fd14b4847004ff087cd132a3e7206c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_283ae970846c49adafc4e36b5404e018"
          }
        },
        "f00568ddfbd64c2dac86edc774272ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_838631a034fc454c86080e8cbe3b5ec1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1500/1500 [00:04&lt;00:00, 304.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a268d018f12c43cfaedc1a872dbf0968"
          }
        },
        "5fd14b4847004ff087cd132a3e7206c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "283ae970846c49adafc4e36b5404e018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "838631a034fc454c86080e8cbe3b5ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a268d018f12c43cfaedc1a872dbf0968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c91b1f47415e43308fe8319315ccf07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed6107f01b30435885fe0be911750009",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a29c9aa28441439db87a2a6995ced6a7",
              "IPY_MODEL_dfec29aea15e40bb8f79bec51af53e4d"
            ]
          }
        },
        "ed6107f01b30435885fe0be911750009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a29c9aa28441439db87a2a6995ced6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dde41332a90441ceb6b44e0ffa438a3e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5949218be01947c3a757c50b3d78b191"
          }
        },
        "dfec29aea15e40bb8f79bec51af53e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db1ce35a04074dc6aacf4d75cad25b93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1500/1500 [00:03&lt;00:00, 437.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdca6d991daa455581f4e93fc66f7a1c"
          }
        },
        "dde41332a90441ceb6b44e0ffa438a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5949218be01947c3a757c50b3d78b191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db1ce35a04074dc6aacf4d75cad25b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdca6d991daa455581f4e93fc66f7a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EesIBF0O2KE"
      },
      "source": [
        "# 라이브러리 불러오기\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import pickle\n",
        "from tensorflow.keras import backend as K\n",
        "from PIL import Image\n",
        "import matplotlib.patches as mpatches\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjmapCbMm8ZB",
        "outputId": "84bd1e66-16d8-449a-ca86-eb6fec1422ee"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 12 02:36:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i06UbyFaO5_P",
        "outputId": "cc85b701-d58b-4e0c-fe12-da9341a439e5"
      },
      "source": [
        "# 구글 드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AXLFiwKO7oO"
      },
      "source": [
        "# 데이터 압축 풀기\n",
        "!unzip -qq /content/drive/MyDrive/DeepPCB-master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6A3jc9HO8bj"
      },
      "source": [
        "# PATH 에 데이터 경로 저장\n",
        "PATH = '/content/DeepPCB-master/PCBData'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "231dbb8a2aee4141a03d9cd0ec0e44fc",
            "c31ae3495ee34d9a8b6c0487fda48308",
            "51c8c5149b0c4794bf59d57c66836601",
            "8155ec6a44144f4283b2d66abf9dc176",
            "6181f3ea4f3c46f4bfbe35381bc58e3e",
            "1f86226652444280b51b9d39fc2c1c84",
            "4eb178bd33f94bb18146db09d8dbb2f7",
            "30fc641b415b4854ac579aa8559cec8a"
          ]
        },
        "id": "0jLJmgjWO9U5",
        "outputId": "47a4c13c-f889-42de-863b-88022f5e96d3"
      },
      "source": [
        "# 데이터를 정상, 불량, 불량분류 list로 나누는 작업\n",
        "# 가장 중요함 데이터 전처리임\n",
        "\n",
        "# os.listdir()은 지정한 디렉토리 내의 모든 파일과 디렉토리의 리스트를 리턴\n",
        "# path_2에 group folder 이름을 저장함\n",
        "\n",
        "#path_2 안에 있는 그룹 폴더 안을 또 들여다 본다\n",
        "#그런데 왜? path가 3,4로 나뉘어지는 것인가...\n",
        "#아하!\n",
        "#group00041 폴더 안으로 들어가게 되면 파일이 2개가 있다.\n",
        "#00041, 00041_not\n",
        "#path_3는 00041, path_4에는 00041_not이 들어가는것이다.\n",
        "\n",
        "#path_3에서 파일 이름에 temp가 있는 경우 -> 정상 이미지\n",
        "#path_3에서 파일 이름에 test가 있는 경우 -> 불량 이미지\n",
        "\n",
        "#따라서 normal list에는 temp 이미지 파일 경로 저장, defect list에는 test 이미지 파일 경로 저장\n",
        "\n",
        "#이제 path_4에는 defect log 를 가진 txt의 파일 경로를 저장한다.\n",
        "\n",
        "#여기서 defect log는 defect의 boundary box 좌표 데이터를 가지고 있다.\n",
        "\n",
        "# 마지막으로 normal defect defectlog 를 sort 해준다.\n",
        "\n",
        "normal = []\n",
        "defect = []\n",
        "defectlog = []\n",
        "path_2 = [os.path.join(PATH,dir) for dir in os.listdir(PATH) if '.' not in dir]\n",
        "for p in tqdm(path_2,total=len(path_2)):\n",
        "    path_3 = os.path.join(p,sorted(os.listdir(p))[0])\n",
        "    normal +=[os.path.join(path_3,dir)for dir in os.listdir(path_3) if 'temp' in dir]\n",
        "    defect +=[os.path.join(path_3,dir)for dir in os.listdir(path_3) if 'test' in dir]\n",
        "    path_4 = os.path.join(p,sorted(os.listdir(p))[1])\n",
        "    defectlog +=[os.path.join(path_4,dir)for dir in os.listdir(path_4)]\n",
        "\n",
        "normal.sort()\n",
        "defect.sort()\n",
        "defectlog.sort()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "231dbb8a2aee4141a03d9cd0ec0e44fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "0bd0d401626449bab2a81f8812b8a3d5",
            "08adf0b25eab4a8481e37ee86d2b401a",
            "c624e6ae5a1c4563b9210fc9a1412442",
            "5f830f0dcf8d44cc89ac64e8620654e7",
            "4c02153c15c24b2aa9748faa4a89f8e1",
            "80bf63542f2e4bda94bbc989a61e81b1",
            "be4c623c62a14edc9521f9589669c097",
            "0cab09b6dc994e43ad3897a9134b1861",
            "ce0a49aaff0a49b5bd47cd5f208457df",
            "4939ec4b9e6c47d88a36009137ad88b1",
            "36f0a3c2c40b463082ab3188ead18301",
            "7be8e36f8b1b46ef9d76d058a8fdd4bd",
            "3d07d3a3a58a4ad69157e1d3ce6dbac3",
            "68318b180c1c4c0abdc2b6c6e4f82efa",
            "60bc3fbf379f4edea9e9ecf2ea908807",
            "ad780477a9d64c65819e5b9b4083102a"
          ]
        },
        "id": "yoqRTo-wPIFL",
        "outputId": "66f49ef5-97ba-4a0e-802b-98beab5c4a47"
      },
      "source": [
        "# normal_img에는 normal한 이미지 데이터들을 array형태로 저장하게 된다.\n",
        "# list로 저장했다가 np.array 형태로 변화 시켜준다\n",
        "\n",
        "# defect_img에는 defect한 이미지 데이터들을 array형태로 저장한다.\n",
        "# 마찬가지로 np.array로 데이터 저장\n",
        "\n",
        "# 두 이미지 모두 resize로 데이터의 크기를 128x128로 설정해준다.\n",
        "\n",
        "normal_img = []\n",
        "defect_img = []\n",
        "for img_path in tqdm(normal,total=len(normal)):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img,(128,128))\n",
        "    normal_img.append(img)\n",
        "for img_path in tqdm(defect,total=len(defect)):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img,(128,128))\n",
        "    defect_img.append(img)\n",
        "normal_img = np.array(normal_img)\n",
        "defect_img = np.array(defect_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bd0d401626449bab2a81f8812b8a3d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1501.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce0a49aaff0a49b5bd47cd5f208457df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viq1Qz77PKZL"
      },
      "source": [
        "# PATH 위치에 img0 img1 의 Array를 pickle 모듈로 저장하는 코드 이다.\n",
        "# pickle 모듈로 저장하는 이유는 array는 따로 불러오거나 읽는게 folder과 다르기 때문이다.\n",
        "\n",
        "with open(PATH+'normal_img.pkl', 'wb') as f:\n",
        "    pickle.dump(normal_img, f, pickle.HIGHEST_PROTOCOL)\n",
        "with open(PATH+'defect_img.pkl', 'wb') as f:\n",
        "    pickle.dump(defect_img, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b9b7e369f0a64b2fbfd759aabf9212f1",
            "146e8c806ad54c00aa7ffe9dfad6e2d4",
            "cc0a2366308b4aa28f849075977bbf0d",
            "a39714d8df19455595371c6949648b4f",
            "921484e88f904e3bac3437a0704a6d7c",
            "596ebed2c31e4e35b99d6ce1177a273d",
            "10ceee2ce91c47c4a95a7f9649156dc2",
            "215139b9aade42848d1c82628e350827"
          ]
        },
        "id": "ozBf53IsivOJ",
        "outputId": "5eb09ea5-4ef5-4e32-f81f-97f47e1adae0"
      },
      "source": [
        "# 이미지 데이터 말고 이제 defect log 데이터를 array에 저장해보자\n",
        "# defet log는 좌표 데이터이다.\n",
        "# x1 y1 x2 y2 즉 사각형 좌표이다.\n",
        "# 그리고 defect는 숫자로 표현 되어있는데, 어떤 defect인지 알려준다.\n",
        "\n",
        "box_point = []\n",
        "i=0\n",
        "for log in tqdm(defectlog,total=len(defectlog)):\n",
        "    temp = pd.read_csv(log,sep=' ' ,names=['x1', 'y1', 'x2', 'y2', 'defect'], header=None).values.tolist()\n",
        "    box_point.append(temp)\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9b7e369f0a64b2fbfd759aabf9212f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "88a554c9ddf64ebfa1ca11348812eed1",
            "86428b7aabb44f4c971dbd6ee0df3248",
            "9b772190c3ca4c1b925ff18571a1faa3",
            "f00568ddfbd64c2dac86edc774272ba9",
            "5fd14b4847004ff087cd132a3e7206c4",
            "283ae970846c49adafc4e36b5404e018",
            "838631a034fc454c86080e8cbe3b5ec1",
            "a268d018f12c43cfaedc1a872dbf0968"
          ]
        },
        "id": "t5fyG_QjjU-t",
        "outputId": "de28bd84-9f6c-4c1a-c12d-de5c269a37cd"
      },
      "source": [
        "# box에는 일단 좌표와 defect저장\n",
        "# 이제 boxarr에 box를 arr로 저장하자\n",
        "# narr 크기는 640x640x1를 0으로 초기화 \n",
        "\n",
        "#cv2.rectangle 공부\n",
        "#cv2.rectangle(img, start, end, color, thickness)\n",
        "#img – 그림을 그릴 이미지\n",
        "#start – 시작 좌표(ex; (0,0))\n",
        "#end – 종료 좌표(ex; (500. 500))\n",
        "#color – BGR형태의 Color(ex; (255, 0, 0) -> Blue)\n",
        "#thickness (int) – 선의 두께. pixel\n",
        "\n",
        "\n",
        "#narr에 그림을 그릴 곳\n",
        "#start좌표는 x1 y1\n",
        "#end 좌표는 x2 y2\n",
        "#color는 d로 했는데 여기서 d는 오류의 종류임\n",
        "#선의 두께 :-1\n",
        "#근데 왜 cv2.resize 88x88로 설정했을까\n",
        "#이게 너무 궁금,,,\n",
        "#boxarr은 target값인데, 마지막으로 나와야하는 size가 88x88라는 말과도 같은거\n",
        "\n",
        "#640x640=409,600\n",
        "#88x88 = 7744\n",
        "\n",
        "#box는 1500개의 리스트 개수\n",
        "#1500개인데 각 리스트 안에 5개씩 값이 있으니까\n",
        "#7500개?\n",
        "\n",
        "\n",
        "#아니 640x640x1 3차원 어레이에 사각형을 그리고 resize를 한다고...?\n",
        "\n",
        "boxarr = []\n",
        "for i in tqdm(range(len(box_point))): #1500번\n",
        "    narr = np.zeros((640,640,1))\n",
        "    for j in range(len(box_point[i])):#5번\n",
        "        x1,y1,x2,y2,d = box_point[i][j]\n",
        "        narr = cv2.rectangle(narr,(x1,y1),(x2,y2),d,-1)\n",
        "    narr = cv2.resize(narr,(88,88))\n",
        "    boxarr.append(narr)\n",
        "boxarr = np.array(boxarr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88a554c9ddf64ebfa1ca11348812eed1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXldB06QjehA",
        "outputId": "20247131-9a50-4906-9e0b-153f6cfa625a"
      },
      "source": [
        "ans1 = np.array(boxarr[0])\n",
        "ans1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 88)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "w0kHtemojl6J",
        "outputId": "7278c8ed-0cac-4e55-aebe-af0b8002ec7e"
      },
      "source": [
        "plt.imshow(boxarr[4],cmap='gnuplot')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "b1ExRVUZjm6t",
        "outputId": "eed6e058-a212-429e-c854-5cce10d86995"
      },
      "source": [
        "plt.imshow(np.reshape(defect_img[4],(128,128)),cmap='gnuplot')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVXDlixDjn86"
      },
      "source": [
        "#dataset은 defect_img이 feature, boxarr이 target\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((defect_img,boxarr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ark5ESy2jxbJ",
        "outputId": "8236c0f3-0995-42a9-cec6-83b1c6cce8b0"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TensorSliceDataset shapes: ((128, 128), (88, 88)), types: (tf.uint8, tf.float64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWI8TPSBjya9"
      },
      "source": [
        "# 총 데이터 개수 n에 저장 (1500개)\n",
        "#dataset 셔플 해줘야함, 재현성을 위해 seed=47로 설정\n",
        "#take(): 해당 배치를 몇 번 불러올지 정한다. \n",
        "#(배치를 1500*0.8 = 1200번 불러온다)\n",
        "#이때 batch 100\n",
        "\n",
        "#test_data는 skip()함수로1200개를 skip\n",
        "\n",
        "#여기서 의문점\n",
        "#dataset.take를 왜 하는거고\n",
        "#data.skip은 또 왜하는거냐\n",
        "#skip은 아에 넘어가는건데...\n",
        "\n",
        "#아 설마\n",
        "#훈련 데이터는 1200개\n",
        "#테스트 데이터는 300개?\n",
        "\n",
        "\n",
        "n=1500\n",
        "dataset = dataset.shuffle(n,seed=47)\n",
        "\n",
        "train_dataset = dataset.take(int(n*0.8)).batch(100)\n",
        "test_dataset = dataset.skip(int(n*0.8)).batch(100)\n",
        "\n",
        "# n=1500\n",
        "# dataset = dataset.shuffle(n,seed=47)\n",
        "\n",
        "# test_dataset = dataset.take(int(n*0.33)).batch(100)\n",
        "# train_dataset = dataset.skip(int(n*0.33)).batch(100)\n",
        "\n",
        "\n",
        "\n",
        "# n=1500\n",
        "# dataset = dataset.shuffle(n,seed=47)\n",
        "\n",
        "# train_dataset_1 = dataset.take(int(n*0.33)).batch(100)\n",
        "# test_dataset = dataset.skip(int(n*0.33)).take(int(n*0.33)).batch(100)\n",
        "# train_dataset_2 = dataset.skip(int(n*0.66)).batch(100)\n",
        "# train_dataset = train_dataset_1.concatenate(train_dataset_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHvMmtZDqGeN",
        "outputId": "87f76ea3-8dcf-4aae-c958-59e2bdfee127"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ShuffleDataset shapes: ((128, 128), (88, 88)), types: (tf.uint8, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1GdVMjj22A",
        "outputId": "0745f695-414c-4cda-897e-4ee30ccb1b78"
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBMNFQe-j4th"
      },
      "source": [
        "## layer5 cnn bn he flip\n",
        "inputs = keras.layers.Input((128,128,1))\n",
        "# x = keras.layers.experimental.preprocessing.Resizing(128,128)(inputs)\n",
        "x = keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "x = keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal_and_vertical')(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #126 126 64\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #124 124 64\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x1 = tf.identity(x)\n",
        "x1 = keras.layers.experimental.preprocessing.CenterCrop(92,92)(x1)\n",
        "\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #62 62,64\n",
        "\n",
        "x = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #60 60 128\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #58 58 128\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x2 = tf.identity(x)\n",
        "x2 = keras.layers.experimental.preprocessing.CenterCrop(50,50)(x2)\n",
        "\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #29 29 128\n",
        "\n",
        "x = keras.layers.Conv2D(filters=256,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #27 27 256\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=256,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #25 25 256\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=2, strides=(2, 2),kernel_initializer=tf.keras.initializers.HeNormal())(x) # 50 50 128\n",
        "\n",
        "x = keras.layers.Concatenate()([x,x2]) #50 50 256\n",
        "x = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #48 48 128\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #46 46 128\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=2, strides=(2, 2),kernel_initializer=tf.keras.initializers.HeNormal())(x) # 92 92 64\n",
        "\n",
        "x = keras.layers.Concatenate()([x,x1]) #92,92 128\n",
        "x = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #90 90 64\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #88 88 64\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "outputs = keras.layers.Conv2D(filters=7,kernel_size=1,kernel_initializer=tf.keras.initializers.HeNormal())(x) #88 88 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdWWvyMe6dYI",
        "outputId": "8837640f-767f-4f37-a04f-186aa5fac128"
      },
      "source": [
        "defect_img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8TayFeu6f2a",
        "outputId": "8d19f93e-3043-44e0-d79b-a70b5847bc97"
      },
      "source": [
        "boxarr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 88, 88)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ree53pJ7jD2",
        "outputId": "acccfa6b-f924-4464-dee5-d274e097e7e6"
      },
      "source": [
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling_1 (Rescaling)         (None, 128, 128, 1)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "random_flip_1 (RandomFlip)      (None, 128, 128, 1)  0           rescaling_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 126, 126, 64) 640         random_flip_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 126, 126, 64) 0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 124, 124, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 124, 124, 64) 0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 60, 60, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 60, 60, 128)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 58, 58, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 58, 58, 128)  0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 29, 29, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 27, 27, 256)  295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 27, 27, 256)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 256)  590080      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 256)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.identity_3 (TFOpLambda)      (None, 58, 58, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 50, 50, 128)  131200      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_crop_3 (CenterCrop)      (None, 50, 50, 128)  0           tf.identity_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 50, 50, 256)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 center_crop_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 48, 48, 128)  295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 48, 48, 128)  0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 46, 46, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 46, 46, 128)  0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.identity_2 (TFOpLambda)      (None, 124, 124, 64) 0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 92, 92, 64)   32832       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_crop_2 (CenterCrop)      (None, 92, 92, 64)   0           tf.identity_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 92, 92, 128)  0           conv2d_transpose_3[0][0]         \n",
            "                                                                 center_crop_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 90, 90, 64)   73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 90, 90, 64)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 88, 88, 64)   36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 88, 88, 64)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 88, 88, 7)    455         activation_19[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,862,087\n",
            "Trainable params: 1,862,087\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_2sNDJEk7Kg"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei8xg7pjk8Og",
        "outputId": "e8669e8c-9a11-47dc-9ea5-350b5311264f"
      },
      "source": [
        "# validation data가 없는데 monitor = 'val_loss'가 맞는 것일까?\n",
        "#es = EarlyStopping(patience=100,monitor='val_loss',min_delta=0.005,mode='min',verbose=1)\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(PATH+'model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch',)\n",
        "history = model.fit(train_dataset,epochs=1000,validation_data=test_dataset,callbacks=callback)\n",
        "#history = model.fit(train_dataset,epochs=500,validation_data=test_dataset,verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 5s 311ms/step - loss: 0.2159 - accuracy: 0.9744 - val_loss: 0.1735 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.17348, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1667 - accuracy: 0.9744 - val_loss: 0.1610 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.17348 to 0.16098, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1591 - accuracy: 0.9746 - val_loss: 0.1596 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.16098 to 0.15964, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1585 - accuracy: 0.9744 - val_loss: 0.1610 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.15964\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1579 - accuracy: 0.9744 - val_loss: 0.1525 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.15964 to 0.15246, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1574 - accuracy: 0.9744 - val_loss: 0.1588 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.15246\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1586 - accuracy: 0.9742 - val_loss: 0.1574 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.15246\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1581 - accuracy: 0.9743 - val_loss: 0.1545 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.15246\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1584 - accuracy: 0.9742 - val_loss: 0.1566 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.15246\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1580 - accuracy: 0.9744 - val_loss: 0.1594 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.15246\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1581 - accuracy: 0.9743 - val_loss: 0.1608 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.15246\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1584 - accuracy: 0.9742 - val_loss: 0.1590 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.15246\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1586 - accuracy: 0.9742 - val_loss: 0.1561 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.15246\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1580 - accuracy: 0.9743 - val_loss: 0.1559 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.15246\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1569 - accuracy: 0.9745 - val_loss: 0.1567 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.15246\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1579 - accuracy: 0.9743 - val_loss: 0.1546 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.15246\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1581 - accuracy: 0.9743 - val_loss: 0.1588 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.15246\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1567 - accuracy: 0.9745 - val_loss: 0.1588 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15246\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1586 - accuracy: 0.9742 - val_loss: 0.1535 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.15246\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.1569 - accuracy: 0.9744 - val_loss: 0.1524 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.15246 to 0.15240, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1571 - accuracy: 0.9744 - val_loss: 0.1549 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.15240\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1575 - accuracy: 0.9743 - val_loss: 0.1531 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.15240\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1567 - accuracy: 0.9745 - val_loss: 0.1497 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.15240 to 0.14970, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.1581 - accuracy: 0.9742 - val_loss: 0.1576 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.14970\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1580 - accuracy: 0.9742 - val_loss: 0.1558 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.14970\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1572 - accuracy: 0.9743 - val_loss: 0.1583 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.14970\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1569 - accuracy: 0.9744 - val_loss: 0.1509 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.14970\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1575 - accuracy: 0.9743 - val_loss: 0.1542 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.14970\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1571 - accuracy: 0.9744 - val_loss: 0.1582 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.14970\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1574 - accuracy: 0.9743 - val_loss: 0.1529 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.14970\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1574 - accuracy: 0.9742 - val_loss: 0.1547 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.14970\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1568 - accuracy: 0.9743 - val_loss: 0.1580 - val_accuracy: 0.9734\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.14970\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1562 - accuracy: 0.9744 - val_loss: 0.1520 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.14970\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1558 - accuracy: 0.9745 - val_loss: 0.1493 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.14970 to 0.14929, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1560 - accuracy: 0.9745 - val_loss: 0.1557 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.14929\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1568 - accuracy: 0.9742 - val_loss: 0.1499 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.14929\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1565 - accuracy: 0.9743 - val_loss: 0.1524 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.14929\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1572 - accuracy: 0.9742 - val_loss: 0.1548 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.14929\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1571 - accuracy: 0.9742 - val_loss: 0.1535 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.14929\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1557 - accuracy: 0.9745 - val_loss: 0.1561 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.14929\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1558 - accuracy: 0.9744 - val_loss: 0.1523 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.14929\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1561 - accuracy: 0.9743 - val_loss: 0.1539 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.14929\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1552 - accuracy: 0.9744 - val_loss: 0.1551 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.14929\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1563 - accuracy: 0.9742 - val_loss: 0.1536 - val_accuracy: 0.9739\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.14929\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1568 - accuracy: 0.9742 - val_loss: 0.1491 - val_accuracy: 0.9745\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.14929 to 0.14913, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1546 - accuracy: 0.9745 - val_loss: 0.1457 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.14913 to 0.14572, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1548 - accuracy: 0.9743 - val_loss: 0.1515 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.14572\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1552 - accuracy: 0.9743 - val_loss: 0.1486 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.14572\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1542 - accuracy: 0.9745 - val_loss: 0.1506 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.14572\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1548 - accuracy: 0.9744 - val_loss: 0.1498 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.14572\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1562 - accuracy: 0.9741 - val_loss: 0.1491 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.14572\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.1554 - accuracy: 0.9742 - val_loss: 0.1505 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.14572\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1547 - accuracy: 0.9742 - val_loss: 0.1451 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.14572 to 0.14514, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1539 - accuracy: 0.9744 - val_loss: 0.1506 - val_accuracy: 0.9736\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.14514\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1544 - accuracy: 0.9743 - val_loss: 0.1486 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.14514\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1544 - accuracy: 0.9742 - val_loss: 0.1444 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.14514 to 0.14435, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1538 - accuracy: 0.9743 - val_loss: 0.1457 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.14435\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1531 - accuracy: 0.9744 - val_loss: 0.1489 - val_accuracy: 0.9737\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.14435\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1536 - accuracy: 0.9742 - val_loss: 0.1438 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.14435 to 0.14382, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1525 - accuracy: 0.9743 - val_loss: 0.1488 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.14382\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1529 - accuracy: 0.9743 - val_loss: 0.1470 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.14382\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1525 - accuracy: 0.9743 - val_loss: 0.1450 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.14382\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1532 - accuracy: 0.9742 - val_loss: 0.1447 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.14382\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1521 - accuracy: 0.9744 - val_loss: 0.1426 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.14382 to 0.14257, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1528 - accuracy: 0.9743 - val_loss: 0.1416 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.14257 to 0.14156, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1523 - accuracy: 0.9743 - val_loss: 0.1396 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.14156 to 0.13963, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1505 - accuracy: 0.9744 - val_loss: 0.1427 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.13963\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1512 - accuracy: 0.9742 - val_loss: 0.1396 - val_accuracy: 0.9743\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.13963 to 0.13958, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1488 - accuracy: 0.9746 - val_loss: 0.1390 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.13958 to 0.13896, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1492 - accuracy: 0.9744 - val_loss: 0.1424 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.13896\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1493 - accuracy: 0.9745 - val_loss: 0.1359 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.13896 to 0.13590, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1494 - accuracy: 0.9745 - val_loss: 0.1395 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.13590\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1488 - accuracy: 0.9744 - val_loss: 0.1352 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.13590 to 0.13524, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1467 - accuracy: 0.9746 - val_loss: 0.1361 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.13524\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1475 - accuracy: 0.9745 - val_loss: 0.1354 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.13524\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1464 - accuracy: 0.9747 - val_loss: 0.1366 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.13524\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1478 - accuracy: 0.9744 - val_loss: 0.1412 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.13524\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1482 - accuracy: 0.9742 - val_loss: 0.1370 - val_accuracy: 0.9741\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.13524\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1453 - accuracy: 0.9744 - val_loss: 0.1344 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.13524 to 0.13443, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1454 - accuracy: 0.9746 - val_loss: 0.1312 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.13443 to 0.13125, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1439 - accuracy: 0.9745 - val_loss: 0.1264 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.13125 to 0.12641, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1419 - accuracy: 0.9747 - val_loss: 0.1296 - val_accuracy: 0.9751\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.12641\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1404 - accuracy: 0.9748 - val_loss: 0.1303 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.12641\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1398 - accuracy: 0.9747 - val_loss: 0.1273 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.12641\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1405 - accuracy: 0.9746 - val_loss: 0.1287 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.12641\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1405 - accuracy: 0.9746 - val_loss: 0.1267 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.12641\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1392 - accuracy: 0.9747 - val_loss: 0.1225 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.12641 to 0.12254, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1396 - accuracy: 0.9746 - val_loss: 0.1228 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.12254\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1372 - accuracy: 0.9749 - val_loss: 0.1237 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.12254\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1367 - accuracy: 0.9746 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.12254 to 0.11925, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1350 - accuracy: 0.9748 - val_loss: 0.1212 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.11925\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1332 - accuracy: 0.9750 - val_loss: 0.1171 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.11925 to 0.11710, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1327 - accuracy: 0.9750 - val_loss: 0.1180 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.11710\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1312 - accuracy: 0.9752 - val_loss: 0.1172 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.11710\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1310 - accuracy: 0.9751 - val_loss: 0.1167 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.11710 to 0.11670, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1302 - accuracy: 0.9752 - val_loss: 0.1160 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.11670 to 0.11604, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1289 - accuracy: 0.9753 - val_loss: 0.1145 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.11604 to 0.11446, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1283 - accuracy: 0.9753 - val_loss: 0.1173 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.11446\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1266 - accuracy: 0.9755 - val_loss: 0.1112 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.11446 to 0.11119, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1243 - accuracy: 0.9756 - val_loss: 0.1088 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.11119 to 0.10884, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1241 - accuracy: 0.9755 - val_loss: 0.1107 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.10884\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1262 - accuracy: 0.9753 - val_loss: 0.1136 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.10884\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1237 - accuracy: 0.9757 - val_loss: 0.1080 - val_accuracy: 0.9759\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.10884 to 0.10799, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1204 - accuracy: 0.9758 - val_loss: 0.1057 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.10799 to 0.10569, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1192 - accuracy: 0.9761 - val_loss: 0.1021 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.10569 to 0.10214, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1190 - accuracy: 0.9759 - val_loss: 0.1014 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.10214 to 0.10136, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1178 - accuracy: 0.9760 - val_loss: 0.1026 - val_accuracy: 0.9774\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.10136\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1156 - accuracy: 0.9762 - val_loss: 0.1001 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.10136 to 0.10013, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1160 - accuracy: 0.9762 - val_loss: 0.0999 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.10013 to 0.09990, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1144 - accuracy: 0.9762 - val_loss: 0.0984 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.09990 to 0.09844, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1122 - accuracy: 0.9766 - val_loss: 0.0987 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.09844\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1131 - accuracy: 0.9764 - val_loss: 0.0952 - val_accuracy: 0.9776\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.09844 to 0.09520, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1088 - accuracy: 0.9768 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.09520 to 0.09236, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1085 - accuracy: 0.9769 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.09236 to 0.09202, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1079 - accuracy: 0.9770 - val_loss: 0.0931 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.09202\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1071 - accuracy: 0.9772 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.09202 to 0.09045, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1084 - accuracy: 0.9770 - val_loss: 0.0915 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.09045\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1058 - accuracy: 0.9772 - val_loss: 0.0906 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.09045\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1063 - accuracy: 0.9772 - val_loss: 0.0905 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.09045\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1050 - accuracy: 0.9772 - val_loss: 0.0884 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.09045 to 0.08837, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1029 - accuracy: 0.9774 - val_loss: 0.0880 - val_accuracy: 0.9784\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.08837 to 0.08804, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.1024 - accuracy: 0.9776 - val_loss: 0.0859 - val_accuracy: 0.9793\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.08804 to 0.08590, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.1017 - accuracy: 0.9776 - val_loss: 0.0828 - val_accuracy: 0.9792\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.08590 to 0.08282, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0994 - accuracy: 0.9779 - val_loss: 0.0824 - val_accuracy: 0.9796\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.08282 to 0.08241, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0976 - accuracy: 0.9781 - val_loss: 0.0839 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.08241\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0968 - accuracy: 0.9782 - val_loss: 0.0797 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00126: val_loss improved from 0.08241 to 0.07965, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0969 - accuracy: 0.9781 - val_loss: 0.0812 - val_accuracy: 0.9799\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.07965\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0960 - accuracy: 0.9782 - val_loss: 0.0786 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.07965 to 0.07857, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0951 - accuracy: 0.9783 - val_loss: 0.0804 - val_accuracy: 0.9796\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.07857\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0942 - accuracy: 0.9785 - val_loss: 0.0793 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.07857\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0934 - accuracy: 0.9786 - val_loss: 0.0806 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.07857\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0939 - accuracy: 0.9784 - val_loss: 0.0756 - val_accuracy: 0.9804\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.07857 to 0.07565, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0918 - accuracy: 0.9787 - val_loss: 0.0767 - val_accuracy: 0.9801\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.07565\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0895 - accuracy: 0.9789 - val_loss: 0.0766 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.07565\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0906 - accuracy: 0.9789 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.07565 to 0.07484, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0884 - accuracy: 0.9792 - val_loss: 0.0721 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00136: val_loss improved from 0.07484 to 0.07206, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0892 - accuracy: 0.9793 - val_loss: 0.0726 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.07206\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0859 - accuracy: 0.9797 - val_loss: 0.0698 - val_accuracy: 0.9815\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.07206 to 0.06976, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.0843 - accuracy: 0.9797 - val_loss: 0.0698 - val_accuracy: 0.9812\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.06976\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0846 - accuracy: 0.9799 - val_loss: 0.0701 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.06976\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0827 - accuracy: 0.9801 - val_loss: 0.0653 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.06976 to 0.06527, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0823 - accuracy: 0.9801 - val_loss: 0.0671 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.06527\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0831 - accuracy: 0.9799 - val_loss: 0.0652 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.06527 to 0.06519, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0821 - accuracy: 0.9801 - val_loss: 0.0678 - val_accuracy: 0.9816\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.06519\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0814 - accuracy: 0.9803 - val_loss: 0.0649 - val_accuracy: 0.9826\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.06519 to 0.06492, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0795 - accuracy: 0.9804 - val_loss: 0.0659 - val_accuracy: 0.9819\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.06492\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0802 - accuracy: 0.9805 - val_loss: 0.0650 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.06492\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0787 - accuracy: 0.9807 - val_loss: 0.0629 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.06492 to 0.06294, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0789 - accuracy: 0.9806 - val_loss: 0.0647 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.06294\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0755 - accuracy: 0.9812 - val_loss: 0.0627 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00150: val_loss improved from 0.06294 to 0.06268, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0763 - accuracy: 0.9809 - val_loss: 0.0638 - val_accuracy: 0.9821\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.06268\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0753 - accuracy: 0.9813 - val_loss: 0.0613 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00152: val_loss improved from 0.06268 to 0.06127, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0749 - accuracy: 0.9812 - val_loss: 0.0576 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00153: val_loss improved from 0.06127 to 0.05765, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0725 - accuracy: 0.9816 - val_loss: 0.0575 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00154: val_loss improved from 0.05765 to 0.05750, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0733 - accuracy: 0.9815 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.05750 to 0.05638, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0721 - accuracy: 0.9816 - val_loss: 0.0580 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.05638\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0734 - accuracy: 0.9815 - val_loss: 0.0616 - val_accuracy: 0.9827\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05638\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0724 - accuracy: 0.9816 - val_loss: 0.0599 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05638\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0718 - accuracy: 0.9816 - val_loss: 0.0547 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.05638 to 0.05474, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0700 - accuracy: 0.9819 - val_loss: 0.0557 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05474\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0693 - accuracy: 0.9820 - val_loss: 0.0548 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05474\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0687 - accuracy: 0.9823 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00162: val_loss improved from 0.05474 to 0.05348, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.0552 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05348\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0689 - accuracy: 0.9823 - val_loss: 0.0536 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05348\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0675 - accuracy: 0.9825 - val_loss: 0.0534 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00165: val_loss improved from 0.05348 to 0.05336, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0671 - accuracy: 0.9825 - val_loss: 0.0538 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.05336\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0662 - accuracy: 0.9827 - val_loss: 0.0519 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.05336 to 0.05190, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0657 - accuracy: 0.9827 - val_loss: 0.0530 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05190\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0660 - accuracy: 0.9827 - val_loss: 0.0494 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.05190 to 0.04945, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0653 - accuracy: 0.9830 - val_loss: 0.0523 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.04945\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.0504 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.04945\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 0.0497 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.04945\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0649 - accuracy: 0.9830 - val_loss: 0.0467 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00173: val_loss improved from 0.04945 to 0.04673, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 0.0490 - val_accuracy: 0.9853\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.04673\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0630 - accuracy: 0.9833 - val_loss: 0.0471 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.04673\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0617 - accuracy: 0.9835 - val_loss: 0.0472 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.04673\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0626 - accuracy: 0.9835 - val_loss: 0.0480 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.04673\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0612 - accuracy: 0.9837 - val_loss: 0.0457 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00178: val_loss improved from 0.04673 to 0.04574, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0590 - accuracy: 0.9841 - val_loss: 0.0473 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.04574\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0602 - accuracy: 0.9838 - val_loss: 0.0468 - val_accuracy: 0.9858\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.04574\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0598 - accuracy: 0.9839 - val_loss: 0.0453 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.04574 to 0.04530, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0596 - accuracy: 0.9840 - val_loss: 0.0456 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.04530\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0595 - accuracy: 0.9840 - val_loss: 0.0448 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.04530 to 0.04475, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00184: val_loss improved from 0.04475 to 0.04372, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0578 - accuracy: 0.9843 - val_loss: 0.0434 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00185: val_loss improved from 0.04372 to 0.04339, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.0439 - val_accuracy: 0.9866\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.04339\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0418 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00187: val_loss improved from 0.04339 to 0.04182, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0568 - accuracy: 0.9844 - val_loss: 0.0421 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.04182\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0572 - accuracy: 0.9846 - val_loss: 0.0402 - val_accuracy: 0.9873\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.04182 to 0.04022, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0570 - accuracy: 0.9845 - val_loss: 0.0420 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.04022\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.04022\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.0437 - val_accuracy: 0.9864\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.04022\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0565 - accuracy: 0.9846 - val_loss: 0.0416 - val_accuracy: 0.9870\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.04022\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0556 - accuracy: 0.9848 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.04022\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.0405 - val_accuracy: 0.9873\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.04022\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.0401 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.04022 to 0.04014, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.0398 - val_accuracy: 0.9873\n",
            "\n",
            "Epoch 00197: val_loss improved from 0.04014 to 0.03979, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0538 - accuracy: 0.9854 - val_loss: 0.0391 - val_accuracy: 0.9876\n",
            "\n",
            "Epoch 00198: val_loss improved from 0.03979 to 0.03911, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0518 - accuracy: 0.9856 - val_loss: 0.0374 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00199: val_loss improved from 0.03911 to 0.03738, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0522 - accuracy: 0.9855 - val_loss: 0.0375 - val_accuracy: 0.9881\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.03738\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0529 - accuracy: 0.9855 - val_loss: 0.0379 - val_accuracy: 0.9879\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.03738\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 0.0397 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.03738\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0517 - accuracy: 0.9858 - val_loss: 0.0367 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00203: val_loss improved from 0.03738 to 0.03669, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0524 - accuracy: 0.9856 - val_loss: 0.0386 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.03669\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0501 - accuracy: 0.9860 - val_loss: 0.0372 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.03669\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0506 - accuracy: 0.9860 - val_loss: 0.0342 - val_accuracy: 0.9887\n",
            "\n",
            "Epoch 00206: val_loss improved from 0.03669 to 0.03418, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.0354 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.03418\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0496 - accuracy: 0.9862 - val_loss: 0.0354 - val_accuracy: 0.9886\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.03418\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0494 - accuracy: 0.9862 - val_loss: 0.0351 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.03418\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0488 - accuracy: 0.9862 - val_loss: 0.0358 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.03418\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0485 - accuracy: 0.9863 - val_loss: 0.0332 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00211: val_loss improved from 0.03418 to 0.03315, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0497 - accuracy: 0.9862 - val_loss: 0.0352 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.03315\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0491 - accuracy: 0.9863 - val_loss: 0.0341 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 0.03315\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0324 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00214: val_loss improved from 0.03315 to 0.03241, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0481 - accuracy: 0.9866 - val_loss: 0.0343 - val_accuracy: 0.9889\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.03241\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0479 - accuracy: 0.9865 - val_loss: 0.0339 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.03241\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.0320 - val_accuracy: 0.9892\n",
            "\n",
            "Epoch 00217: val_loss improved from 0.03241 to 0.03200, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0480 - accuracy: 0.9866 - val_loss: 0.0336 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.03200\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.0334 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.03200\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0468 - accuracy: 0.9869 - val_loss: 0.0325 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.03200\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.0316 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00221: val_loss improved from 0.03200 to 0.03157, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0454 - accuracy: 0.9872 - val_loss: 0.0348 - val_accuracy: 0.9888\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.03157\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.0314 - val_accuracy: 0.9896\n",
            "\n",
            "Epoch 00223: val_loss improved from 0.03157 to 0.03136, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.0309 - val_accuracy: 0.9900\n",
            "\n",
            "Epoch 00224: val_loss improved from 0.03136 to 0.03089, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0453 - accuracy: 0.9873 - val_loss: 0.0333 - val_accuracy: 0.9894\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.03089\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0460 - accuracy: 0.9871 - val_loss: 0.0321 - val_accuracy: 0.9896\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.03089\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 0.0328 - val_accuracy: 0.9892\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.03089\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0310 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.03089\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.0317 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.03089\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.0325 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.03089\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.0294 - val_accuracy: 0.9903\n",
            "\n",
            "Epoch 00231: val_loss improved from 0.03089 to 0.02941, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.0305 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.02941\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 0.0306 - val_accuracy: 0.9896\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.02941\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0432 - accuracy: 0.9878 - val_loss: 0.0303 - val_accuracy: 0.9901\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.02941\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0427 - accuracy: 0.9881 - val_loss: 0.0312 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.02941\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.0297 - val_accuracy: 0.9900\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 0.02941\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0425 - accuracy: 0.9879 - val_loss: 0.0306 - val_accuracy: 0.9898\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.02941\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0422 - accuracy: 0.9881 - val_loss: 0.0298 - val_accuracy: 0.9900\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 0.02941\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0427 - accuracy: 0.9879 - val_loss: 0.0282 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00239: val_loss improved from 0.02941 to 0.02824, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0423 - accuracy: 0.9880 - val_loss: 0.0292 - val_accuracy: 0.9901\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 0.02824\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0283 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.02824\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.0279 - val_accuracy: 0.9902\n",
            "\n",
            "Epoch 00242: val_loss improved from 0.02824 to 0.02791, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0418 - accuracy: 0.9880 - val_loss: 0.0292 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.02791\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0265 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00244: val_loss improved from 0.02791 to 0.02647, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0398 - accuracy: 0.9886 - val_loss: 0.0273 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.02647\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0419 - accuracy: 0.9882 - val_loss: 0.0265 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 0.02647\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0280 - val_accuracy: 0.9906\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.02647\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 0.0288 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.02647\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9903\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 0.02647\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.0287 - val_accuracy: 0.9903\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 0.02647\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0260 - val_accuracy: 0.9908\n",
            "\n",
            "Epoch 00251: val_loss improved from 0.02647 to 0.02598, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.0286 - val_accuracy: 0.9906\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.02598\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.0275 - val_accuracy: 0.9906\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.02598\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.0268 - val_accuracy: 0.9909\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.02598\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0400 - accuracy: 0.9886 - val_loss: 0.0271 - val_accuracy: 0.9909\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.02598\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 0.0284 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.02598\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0388 - accuracy: 0.9889 - val_loss: 0.0273 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.02598\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0387 - accuracy: 0.9889 - val_loss: 0.0268 - val_accuracy: 0.9909\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.02598\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 0.0266 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.02598\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 0.0263 - val_accuracy: 0.9908\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.02598\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0259 - val_accuracy: 0.9911\n",
            "\n",
            "Epoch 00261: val_loss improved from 0.02598 to 0.02594, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 0.0253 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00262: val_loss improved from 0.02594 to 0.02528, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0379 - accuracy: 0.9891 - val_loss: 0.0254 - val_accuracy: 0.9911\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.02528\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0374 - accuracy: 0.9891 - val_loss: 0.0265 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.02528\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.0257 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.02528\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0252 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00266: val_loss improved from 0.02528 to 0.02517, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0260 - val_accuracy: 0.9914\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.02517\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 0.0246 - val_accuracy: 0.9917\n",
            "\n",
            "Epoch 00268: val_loss improved from 0.02517 to 0.02461, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0242 - val_accuracy: 0.9917\n",
            "\n",
            "Epoch 00269: val_loss improved from 0.02461 to 0.02424, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.0244 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.02424\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0376 - accuracy: 0.9892 - val_loss: 0.0243 - val_accuracy: 0.9918\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.02424\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0230 - val_accuracy: 0.9919\n",
            "\n",
            "Epoch 00272: val_loss improved from 0.02424 to 0.02304, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 0.0240 - val_accuracy: 0.9918\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.02304\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0372 - accuracy: 0.9893 - val_loss: 0.0250 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.02304\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0244 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.02304\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0244 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.02304\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.0226 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00277: val_loss improved from 0.02304 to 0.02263, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.0225 - val_accuracy: 0.9921\n",
            "\n",
            "Epoch 00278: val_loss improved from 0.02263 to 0.02251, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 0.0230 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 0.02251\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 0.0227 - val_accuracy: 0.9921\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 0.02251\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0359 - accuracy: 0.9897 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 0.02251\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.0221 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00282: val_loss improved from 0.02251 to 0.02206, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0233 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 0.02206\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.0232 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 0.02206\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.0221 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00285: val_loss improved from 0.02206 to 0.02206, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 0.02206\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.0227 - val_accuracy: 0.9921\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 0.02206\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0344 - accuracy: 0.9901 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 0.02206\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.0220 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00289: val_loss improved from 0.02206 to 0.02200, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 0.02200\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.0214 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00291: val_loss improved from 0.02200 to 0.02144, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.0221 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 0.02144\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 0.02144\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0217 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 0.02144\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0218 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 0.02144\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0216 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 0.02144\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0347 - accuracy: 0.9901 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 0.02144\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0219 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 0.02144\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.0217 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 0.02144\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 0.0219 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 0.02144\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0212 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00301: val_loss improved from 0.02144 to 0.02118, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00302: val_loss did not improve from 0.02118\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.0207 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00303: val_loss improved from 0.02118 to 0.02069, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00304: val_loss did not improve from 0.02069\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0207 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00305: val_loss did not improve from 0.02069\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.0207 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00306: val_loss did not improve from 0.02069\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0331 - accuracy: 0.9905 - val_loss: 0.0201 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00307: val_loss improved from 0.02069 to 0.02005, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.0214 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00308: val_loss did not improve from 0.02005\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.0200 - val_accuracy: 0.9929\n",
            "\n",
            "Epoch 00309: val_loss improved from 0.02005 to 0.01997, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0212 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00310: val_loss did not improve from 0.01997\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.0206 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00311: val_loss did not improve from 0.01997\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0206 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00312: val_loss did not improve from 0.01997\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0212 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00313: val_loss did not improve from 0.01997\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0217 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00314: val_loss did not improve from 0.01997\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.0213 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00315: val_loss did not improve from 0.01997\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0211 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00316: val_loss did not improve from 0.01997\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.0211 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00317: val_loss did not improve from 0.01997\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.0215 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00318: val_loss did not improve from 0.01997\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.0201 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00319: val_loss did not improve from 0.01997\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0326 - accuracy: 0.9904 - val_loss: 0.0231 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00320: val_loss did not improve from 0.01997\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 0.0222 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00321: val_loss did not improve from 0.01997\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.0200 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00322: val_loss did not improve from 0.01997\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0202 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00323: val_loss did not improve from 0.01997\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0191 - val_accuracy: 0.9931\n",
            "\n",
            "Epoch 00324: val_loss improved from 0.01997 to 0.01910, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.0207 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00325: val_loss did not improve from 0.01910\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0320 - accuracy: 0.9907 - val_loss: 0.0200 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00326: val_loss did not improve from 0.01910\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0337 - accuracy: 0.9904 - val_loss: 0.0223 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00327: val_loss did not improve from 0.01910\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 0.0209 - val_accuracy: 0.9924\n",
            "\n",
            "Epoch 00328: val_loss did not improve from 0.01910\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0202 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00329: val_loss did not improve from 0.01910\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00330: val_loss improved from 0.01910 to 0.01849, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.0203 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00331: val_loss did not improve from 0.01849\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.0196 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00332: val_loss did not improve from 0.01849\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0195 - val_accuracy: 0.9927\n",
            "\n",
            "Epoch 00333: val_loss did not improve from 0.01849\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0307 - accuracy: 0.9910 - val_loss: 0.0202 - val_accuracy: 0.9925\n",
            "\n",
            "Epoch 00334: val_loss did not improve from 0.01849\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0183 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00335: val_loss improved from 0.01849 to 0.01830, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.0193 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00336: val_loss did not improve from 0.01830\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0187 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00337: val_loss did not improve from 0.01830\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0310 - accuracy: 0.9910 - val_loss: 0.0183 - val_accuracy: 0.9931\n",
            "\n",
            "Epoch 00338: val_loss did not improve from 0.01830\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0192 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00339: val_loss did not improve from 0.01830\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 0.0187 - val_accuracy: 0.9934\n",
            "\n",
            "Epoch 00340: val_loss did not improve from 0.01830\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.0184 - val_accuracy: 0.9932\n",
            "\n",
            "Epoch 00341: val_loss did not improve from 0.01830\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.0184 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00342: val_loss did not improve from 0.01830\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.0184 - val_accuracy: 0.9934\n",
            "\n",
            "Epoch 00343: val_loss did not improve from 0.01830\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.0168 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00344: val_loss improved from 0.01830 to 0.01679, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.0182 - val_accuracy: 0.9933\n",
            "\n",
            "Epoch 00345: val_loss did not improve from 0.01679\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.0173 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00346: val_loss did not improve from 0.01679\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.0166 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00347: val_loss improved from 0.01679 to 0.01655, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0179 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00348: val_loss did not improve from 0.01655\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.0176 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00349: val_loss did not improve from 0.01655\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.0166 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00350: val_loss did not improve from 0.01655\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.0163 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00351: val_loss improved from 0.01655 to 0.01628, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.0162 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00352: val_loss improved from 0.01628 to 0.01618, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0171 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00353: val_loss did not improve from 0.01618\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0168 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00354: val_loss did not improve from 0.01618\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.0169 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00355: val_loss did not improve from 0.01618\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0169 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00356: val_loss did not improve from 0.01618\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0168 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00357: val_loss did not improve from 0.01618\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00358: val_loss did not improve from 0.01618\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0160 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00359: val_loss improved from 0.01618 to 0.01604, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0293 - accuracy: 0.9914 - val_loss: 0.0172 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00360: val_loss did not improve from 0.01604\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0164 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00361: val_loss did not improve from 0.01604\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0170 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00362: val_loss did not improve from 0.01604\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00363: val_loss did not improve from 0.01604\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0176 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00364: val_loss did not improve from 0.01604\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00365: val_loss did not improve from 0.01604\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0166 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00366: val_loss did not improve from 0.01604\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 0.0167 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00367: val_loss did not improve from 0.01604\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0170 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00368: val_loss did not improve from 0.01604\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0164 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00369: val_loss did not improve from 0.01604\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0166 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00370: val_loss did not improve from 0.01604\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00371: val_loss did not improve from 0.01604\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0172 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00372: val_loss did not improve from 0.01604\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0171 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00373: val_loss did not improve from 0.01604\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.0157 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00374: val_loss improved from 0.01604 to 0.01570, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0155 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00375: val_loss improved from 0.01570 to 0.01550, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0164 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00376: val_loss did not improve from 0.01550\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0164 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00377: val_loss did not improve from 0.01550\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0153 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00378: val_loss improved from 0.01550 to 0.01530, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0163 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00379: val_loss did not improve from 0.01530\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.0153 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00380: val_loss did not improve from 0.01530\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.0151 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00381: val_loss improved from 0.01530 to 0.01508, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0164 - val_accuracy: 0.9939\n",
            "\n",
            "Epoch 00382: val_loss did not improve from 0.01508\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0167 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00383: val_loss did not improve from 0.01508\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0155 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00384: val_loss did not improve from 0.01508\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0173 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00385: val_loss did not improve from 0.01508\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0152 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00386: val_loss did not improve from 0.01508\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.0151 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00387: val_loss did not improve from 0.01508\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.0159 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00388: val_loss did not improve from 0.01508\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 4s 297ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0161 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00389: val_loss did not improve from 0.01508\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 4s 289ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0162 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00390: val_loss did not improve from 0.01508\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.0157 - val_accuracy: 0.9938\n",
            "\n",
            "Epoch 00391: val_loss did not improve from 0.01508\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0160 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00392: val_loss did not improve from 0.01508\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0162 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00393: val_loss did not improve from 0.01508\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0152 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00394: val_loss did not improve from 0.01508\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0156 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00395: val_loss did not improve from 0.01508\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00396: val_loss did not improve from 0.01508\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.0152 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00397: val_loss did not improve from 0.01508\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0171 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00398: val_loss did not improve from 0.01508\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 0.01508\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0155 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00400: val_loss did not improve from 0.01508\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0148 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00401: val_loss improved from 0.01508 to 0.01477, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0157 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00402: val_loss did not improve from 0.01477\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0159 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00403: val_loss did not improve from 0.01477\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0158 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00404: val_loss did not improve from 0.01477\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00405: val_loss did not improve from 0.01477\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.0144 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00406: val_loss improved from 0.01477 to 0.01438, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0157 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00407: val_loss did not improve from 0.01438\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0140 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00408: val_loss improved from 0.01438 to 0.01405, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0141 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00409: val_loss did not improve from 0.01405\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0141 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00410: val_loss did not improve from 0.01405\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0148 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00411: val_loss did not improve from 0.01405\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0145 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00412: val_loss did not improve from 0.01405\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0149 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00413: val_loss did not improve from 0.01405\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.0151 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00414: val_loss did not improve from 0.01405\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 0.0146 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00415: val_loss did not improve from 0.01405\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.0155 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00416: val_loss did not improve from 0.01405\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0258 - accuracy: 0.9922 - val_loss: 0.0140 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00417: val_loss improved from 0.01405 to 0.01396, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0141 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00418: val_loss did not improve from 0.01396\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0145 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00419: val_loss did not improve from 0.01396\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0155 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00420: val_loss did not improve from 0.01396\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.0137 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00421: val_loss improved from 0.01396 to 0.01366, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0135 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00422: val_loss improved from 0.01366 to 0.01352, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0145 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00423: val_loss did not improve from 0.01352\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0137 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00424: val_loss did not improve from 0.01352\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0137 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00425: val_loss did not improve from 0.01352\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0147 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00426: val_loss did not improve from 0.01352\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00427: val_loss did not improve from 0.01352\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0140 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00428: val_loss did not improve from 0.01352\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0135 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00429: val_loss improved from 0.01352 to 0.01352, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0133 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00430: val_loss improved from 0.01352 to 0.01326, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00431: val_loss improved from 0.01326 to 0.01250, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0141 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00432: val_loss did not improve from 0.01250\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0136 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00433: val_loss did not improve from 0.01250\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0122 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00434: val_loss improved from 0.01250 to 0.01221, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0133 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00435: val_loss did not improve from 0.01221\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00436: val_loss did not improve from 0.01221\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0138 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00437: val_loss did not improve from 0.01221\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.0125 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00438: val_loss did not improve from 0.01221\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0147 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00439: val_loss did not improve from 0.01221\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0126 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00440: val_loss did not improve from 0.01221\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0133 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00441: val_loss did not improve from 0.01221\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00442: val_loss did not improve from 0.01221\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0130 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00443: val_loss did not improve from 0.01221\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0121 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00444: val_loss improved from 0.01221 to 0.01208, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0141 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00445: val_loss did not improve from 0.01208\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00446: val_loss did not improve from 0.01208\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0144 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00447: val_loss did not improve from 0.01208\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0119 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00448: val_loss improved from 0.01208 to 0.01191, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0134 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00449: val_loss did not improve from 0.01191\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0132 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00450: val_loss did not improve from 0.01191\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0119 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00451: val_loss improved from 0.01191 to 0.01186, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0136 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00452: val_loss did not improve from 0.01186\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00453: val_loss did not improve from 0.01186\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0123 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00454: val_loss did not improve from 0.01186\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0139 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00455: val_loss did not improve from 0.01186\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.0119 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00456: val_loss did not improve from 0.01186\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0124 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00457: val_loss did not improve from 0.01186\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0117 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00458: val_loss improved from 0.01186 to 0.01168, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0124 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00459: val_loss did not improve from 0.01168\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00460: val_loss did not improve from 0.01168\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0116 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00461: val_loss improved from 0.01168 to 0.01165, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0117 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00462: val_loss did not improve from 0.01165\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0126 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00463: val_loss did not improve from 0.01165\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00464: val_loss did not improve from 0.01165\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0126 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00465: val_loss did not improve from 0.01165\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0128 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00466: val_loss did not improve from 0.01165\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.0127 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00467: val_loss did not improve from 0.01165\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0122 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00468: val_loss did not improve from 0.01165\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00469: val_loss did not improve from 0.01165\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00470: val_loss did not improve from 0.01165\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0128 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00471: val_loss did not improve from 0.01165\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0138 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00472: val_loss did not improve from 0.01165\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0125 - val_accuracy: 0.9944\n",
            "\n",
            "Epoch 00473: val_loss did not improve from 0.01165\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0127 - val_accuracy: 0.9947\n",
            "\n",
            "Epoch 00474: val_loss did not improve from 0.01165\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00475: val_loss did not improve from 0.01165\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0118 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00476: val_loss did not improve from 0.01165\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0125 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 0.01165\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0121 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00478: val_loss did not improve from 0.01165\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0112 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00479: val_loss improved from 0.01165 to 0.01124, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0115 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00480: val_loss did not improve from 0.01124\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0121 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00481: val_loss did not improve from 0.01124\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0127 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00482: val_loss did not improve from 0.01124\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00483: val_loss did not improve from 0.01124\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00484: val_loss did not improve from 0.01124\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0120 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00485: val_loss did not improve from 0.01124\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00486: val_loss did not improve from 0.01124\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00487: val_loss improved from 0.01124 to 0.00997, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00488: val_loss did not improve from 0.00997\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00489: val_loss did not improve from 0.00997\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0121 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00490: val_loss did not improve from 0.00997\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0121 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 0.00997\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0110 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 0.00997\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0112 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00493: val_loss did not improve from 0.00997\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0117 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00494: val_loss did not improve from 0.00997\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0109 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00495: val_loss did not improve from 0.00997\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0109 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00496: val_loss did not improve from 0.00997\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0108 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00497: val_loss did not improve from 0.00997\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0119 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00498: val_loss did not improve from 0.00997\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0115 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00499: val_loss did not improve from 0.00997\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0118 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00500: val_loss did not improve from 0.00997\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0118 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00501: val_loss did not improve from 0.00997\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0114 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00502: val_loss did not improve from 0.00997\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0115 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00503: val_loss did not improve from 0.00997\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0106 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00504: val_loss did not improve from 0.00997\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0110 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00505: val_loss did not improve from 0.00997\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0109 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00506: val_loss did not improve from 0.00997\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0121 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00507: val_loss did not improve from 0.00997\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0106 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00508: val_loss did not improve from 0.00997\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0112 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00509: val_loss did not improve from 0.00997\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0116 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00510: val_loss did not improve from 0.00997\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0112 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00511: val_loss did not improve from 0.00997\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00512: val_loss did not improve from 0.00997\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0118 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00513: val_loss did not improve from 0.00997\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0114 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00514: val_loss did not improve from 0.00997\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0103 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00515: val_loss did not improve from 0.00997\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0114 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00516: val_loss did not improve from 0.00997\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0113 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00517: val_loss did not improve from 0.00997\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0114 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00518: val_loss did not improve from 0.00997\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0106 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00519: val_loss did not improve from 0.00997\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00520: val_loss did not improve from 0.00997\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0106 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00521: val_loss did not improve from 0.00997\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0108 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00522: val_loss did not improve from 0.00997\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0122 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00523: val_loss did not improve from 0.00997\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0106 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00524: val_loss did not improve from 0.00997\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00525: val_loss did not improve from 0.00997\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0114 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00526: val_loss did not improve from 0.00997\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0116 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00527: val_loss did not improve from 0.00997\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0109 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00528: val_loss did not improve from 0.00997\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0112 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00529: val_loss did not improve from 0.00997\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0113 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00530: val_loss did not improve from 0.00997\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00531: val_loss did not improve from 0.00997\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0110 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00532: val_loss did not improve from 0.00997\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0112 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00533: val_loss did not improve from 0.00997\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0113 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 0.00997\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0096 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00535: val_loss improved from 0.00997 to 0.00960, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00536: val_loss did not improve from 0.00960\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0117 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00537: val_loss did not improve from 0.00960\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0108 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00538: val_loss did not improve from 0.00960\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0106 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00539: val_loss did not improve from 0.00960\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0107 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00540: val_loss did not improve from 0.00960\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0117 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00541: val_loss did not improve from 0.00960\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0104 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00542: val_loss did not improve from 0.00960\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00543: val_loss improved from 0.00960 to 0.00947, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0110 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00544: val_loss did not improve from 0.00947\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00545: val_loss did not improve from 0.00947\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0097 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00546: val_loss did not improve from 0.00947\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0100 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00547: val_loss did not improve from 0.00947\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0101 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00548: val_loss did not improve from 0.00947\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0092 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00549: val_loss improved from 0.00947 to 0.00920, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0094 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00550: val_loss did not improve from 0.00920\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0109 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00551: val_loss did not improve from 0.00920\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0102 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00552: val_loss did not improve from 0.00920\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0102 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00553: val_loss did not improve from 0.00920\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00554: val_loss did not improve from 0.00920\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0102 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00555: val_loss did not improve from 0.00920\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00556: val_loss did not improve from 0.00920\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0109 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00557: val_loss did not improve from 0.00920\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0102 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00558: val_loss did not improve from 0.00920\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0113 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00559: val_loss did not improve from 0.00920\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0108 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00560: val_loss did not improve from 0.00920\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0095 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00561: val_loss did not improve from 0.00920\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0109 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00562: val_loss did not improve from 0.00920\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00563: val_loss did not improve from 0.00920\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0108 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00564: val_loss did not improve from 0.00920\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0104 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00565: val_loss did not improve from 0.00920\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0098 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00566: val_loss did not improve from 0.00920\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00567: val_loss did not improve from 0.00920\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0108 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00568: val_loss did not improve from 0.00920\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 0.00920\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0104 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 0.00920\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0098 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00571: val_loss did not improve from 0.00920\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0103 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00572: val_loss did not improve from 0.00920\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0111 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00573: val_loss did not improve from 0.00920\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0106 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00574: val_loss did not improve from 0.00920\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0102 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00575: val_loss did not improve from 0.00920\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0099 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00576: val_loss did not improve from 0.00920\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0099 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00577: val_loss did not improve from 0.00920\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0103 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00578: val_loss did not improve from 0.00920\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0107 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00579: val_loss did not improve from 0.00920\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0093 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00580: val_loss did not improve from 0.00920\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00581: val_loss did not improve from 0.00920\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00582: val_loss did not improve from 0.00920\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0107 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00583: val_loss did not improve from 0.00920\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0101 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00584: val_loss did not improve from 0.00920\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0097 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 0.00920\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0092 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00586: val_loss did not improve from 0.00920\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0094 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00587: val_loss did not improve from 0.00920\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0096 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 0.00920\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0104 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 0.00920\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0098 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 0.00920\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00591: val_loss did not improve from 0.00920\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0092 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00592: val_loss did not improve from 0.00920\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0091 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00593: val_loss improved from 0.00920 to 0.00910, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0097 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00594: val_loss did not improve from 0.00910\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 0.00910\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0090 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00596: val_loss improved from 0.00910 to 0.00904, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0097 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00597: val_loss did not improve from 0.00904\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00598: val_loss improved from 0.00904 to 0.00864, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0091 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00599: val_loss did not improve from 0.00864\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0102 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00600: val_loss did not improve from 0.00864\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0102 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00601: val_loss did not improve from 0.00864\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0094 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00602: val_loss did not improve from 0.00864\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0092 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 0.00864\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0102 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00604: val_loss did not improve from 0.00864\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0096 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00605: val_loss did not improve from 0.00864\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0088 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00606: val_loss did not improve from 0.00864\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0090 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00607: val_loss did not improve from 0.00864\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0093 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 0.00864\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0092 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00609: val_loss did not improve from 0.00864\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0093 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 0.00864\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0087 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00611: val_loss did not improve from 0.00864\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00612: val_loss improved from 0.00864 to 0.00863, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0082 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00613: val_loss improved from 0.00863 to 0.00820, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0080 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00614: val_loss improved from 0.00820 to 0.00797, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00615: val_loss did not improve from 0.00797\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0089 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00616: val_loss did not improve from 0.00797\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0096 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00617: val_loss did not improve from 0.00797\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0097 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00618: val_loss did not improve from 0.00797\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00619: val_loss did not improve from 0.00797\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0086 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00620: val_loss did not improve from 0.00797\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0091 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 0.00797\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0087 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 0.00797\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0090 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 0.00797\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0091 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 0.00797\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0097 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00625: val_loss did not improve from 0.00797\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0087 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00626: val_loss did not improve from 0.00797\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00627: val_loss did not improve from 0.00797\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00628: val_loss did not improve from 0.00797\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00629: val_loss did not improve from 0.00797\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0096 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00630: val_loss did not improve from 0.00797\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0091 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 0.00797\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0086 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 0.00797\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0093 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00633: val_loss did not improve from 0.00797\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0088 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 0.00797\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0094 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 0.00797\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 0.00797\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0080 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 0.00797\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0088 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00638: val_loss did not improve from 0.00797\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0092 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00639: val_loss did not improve from 0.00797\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0094 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00640: val_loss did not improve from 0.00797\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0090 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00641: val_loss did not improve from 0.00797\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0088 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00642: val_loss did not improve from 0.00797\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0084 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 0.00797\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0100 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00644: val_loss did not improve from 0.00797\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0107 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00645: val_loss did not improve from 0.00797\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0096 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00646: val_loss did not improve from 0.00797\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0091 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00647: val_loss did not improve from 0.00797\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0097 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00648: val_loss did not improve from 0.00797\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0097 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00649: val_loss did not improve from 0.00797\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0081 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 0.00797\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0095 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00651: val_loss did not improve from 0.00797\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 0.00797\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0091 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 0.00797\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0085 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00654: val_loss did not improve from 0.00797\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0089 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00655: val_loss did not improve from 0.00797\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0091 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 0.00797\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0088 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 0.00797\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00658: val_loss improved from 0.00797 to 0.00793, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0077 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00659: val_loss improved from 0.00793 to 0.00772, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0076 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00660: val_loss improved from 0.00772 to 0.00759, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0089 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00661: val_loss did not improve from 0.00759\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0095 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00662: val_loss did not improve from 0.00759\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0085 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00663: val_loss did not improve from 0.00759\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0092 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00664: val_loss did not improve from 0.00759\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00665: val_loss did not improve from 0.00759\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0090 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 0.00759\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0088 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 0.00759\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 0.00759\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0081 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 0.00759\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0094 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 0.00759\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0084 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 0.00759\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 0.00759\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0081 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00673: val_loss did not improve from 0.00759\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0085 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00674: val_loss did not improve from 0.00759\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.0089 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00675: val_loss did not improve from 0.00759\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0069 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00676: val_loss improved from 0.00759 to 0.00695, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0086 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00677: val_loss did not improve from 0.00695\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00678: val_loss did not improve from 0.00695\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0079 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00679: val_loss did not improve from 0.00695\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0084 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00680: val_loss did not improve from 0.00695\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00681: val_loss did not improve from 0.00695\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0087 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 0.00695\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0085 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 0.00695\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0081 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 0.00695\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00685: val_loss did not improve from 0.00695\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0078 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00686: val_loss did not improve from 0.00695\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00687: val_loss did not improve from 0.00695\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00688: val_loss did not improve from 0.00695\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0083 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 0.00695\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0081 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 0.00695\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0085 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 0.00695\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00692: val_loss did not improve from 0.00695\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0083 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 0.00695\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0084 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 0.00695\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0085 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00695: val_loss did not improve from 0.00695\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0087 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00696: val_loss did not improve from 0.00695\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0078 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00697: val_loss did not improve from 0.00695\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00698: val_loss did not improve from 0.00695\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0081 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00699: val_loss did not improve from 0.00695\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0086 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00700: val_loss did not improve from 0.00695\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00701: val_loss did not improve from 0.00695\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0086 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00702: val_loss did not improve from 0.00695\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0077 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00703: val_loss did not improve from 0.00695\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0095 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00704: val_loss did not improve from 0.00695\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0078 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00705: val_loss did not improve from 0.00695\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00706: val_loss did not improve from 0.00695\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00707: val_loss did not improve from 0.00695\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0081 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00708: val_loss did not improve from 0.00695\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0096 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00709: val_loss did not improve from 0.00695\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0077 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00710: val_loss did not improve from 0.00695\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0081 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00711: val_loss did not improve from 0.00695\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0091 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00712: val_loss did not improve from 0.00695\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0078 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00713: val_loss did not improve from 0.00695\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00714: val_loss did not improve from 0.00695\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0081 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00715: val_loss did not improve from 0.00695\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00716: val_loss did not improve from 0.00695\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00717: val_loss did not improve from 0.00695\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0088 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00718: val_loss did not improve from 0.00695\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0079 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00719: val_loss did not improve from 0.00695\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00720: val_loss did not improve from 0.00695\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0073 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00721: val_loss did not improve from 0.00695\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00722: val_loss did not improve from 0.00695\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00723: val_loss did not improve from 0.00695\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00724: val_loss did not improve from 0.00695\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00725: val_loss improved from 0.00695 to 0.00683, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00726: val_loss did not improve from 0.00683\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00727: val_loss did not improve from 0.00683\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0067 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00728: val_loss improved from 0.00683 to 0.00671, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0070 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00729: val_loss did not improve from 0.00671\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0076 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00730: val_loss did not improve from 0.00671\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00731: val_loss did not improve from 0.00671\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0076 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00732: val_loss did not improve from 0.00671\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0085 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00733: val_loss did not improve from 0.00671\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00734: val_loss did not improve from 0.00671\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0082 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00735: val_loss did not improve from 0.00671\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00736: val_loss did not improve from 0.00671\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0084 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00737: val_loss did not improve from 0.00671\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0081 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00738: val_loss did not improve from 0.00671\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00739: val_loss did not improve from 0.00671\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0080 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00740: val_loss did not improve from 0.00671\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00741: val_loss did not improve from 0.00671\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00742: val_loss did not improve from 0.00671\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00743: val_loss did not improve from 0.00671\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0070 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00744: val_loss did not improve from 0.00671\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0069 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00745: val_loss did not improve from 0.00671\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00746: val_loss did not improve from 0.00671\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0082 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00747: val_loss did not improve from 0.00671\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0084 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00748: val_loss did not improve from 0.00671\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0084 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00749: val_loss did not improve from 0.00671\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0089 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00750: val_loss did not improve from 0.00671\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0090 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00751: val_loss did not improve from 0.00671\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00752: val_loss did not improve from 0.00671\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0078 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00753: val_loss did not improve from 0.00671\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0079 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00754: val_loss did not improve from 0.00671\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0082 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00755: val_loss did not improve from 0.00671\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0083 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00756: val_loss did not improve from 0.00671\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0073 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00757: val_loss did not improve from 0.00671\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0078 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00758: val_loss did not improve from 0.00671\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0084 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00759: val_loss did not improve from 0.00671\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0083 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00760: val_loss did not improve from 0.00671\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0080 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00761: val_loss did not improve from 0.00671\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0080 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00762: val_loss did not improve from 0.00671\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0088 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00763: val_loss did not improve from 0.00671\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0084 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00764: val_loss did not improve from 0.00671\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0073 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00765: val_loss did not improve from 0.00671\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00766: val_loss did not improve from 0.00671\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0090 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00767: val_loss did not improve from 0.00671\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0086 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00768: val_loss did not improve from 0.00671\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0087 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00769: val_loss did not improve from 0.00671\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00770: val_loss did not improve from 0.00671\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0075 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00771: val_loss did not improve from 0.00671\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00772: val_loss did not improve from 0.00671\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0088 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00773: val_loss did not improve from 0.00671\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0080 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00774: val_loss did not improve from 0.00671\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0085 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00775: val_loss did not improve from 0.00671\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.0079 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00776: val_loss did not improve from 0.00671\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0079 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00777: val_loss did not improve from 0.00671\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0077 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00778: val_loss did not improve from 0.00671\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0078 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00779: val_loss did not improve from 0.00671\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0078 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00780: val_loss did not improve from 0.00671\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0076 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00781: val_loss did not improve from 0.00671\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0073 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00782: val_loss did not improve from 0.00671\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0065 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00783: val_loss improved from 0.00671 to 0.00652, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0073 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00784: val_loss did not improve from 0.00652\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0075 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00785: val_loss did not improve from 0.00652\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00786: val_loss did not improve from 0.00652\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0077 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00787: val_loss did not improve from 0.00652\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0074 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00788: val_loss did not improve from 0.00652\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0075 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00789: val_loss did not improve from 0.00652\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00790: val_loss did not improve from 0.00652\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00791: val_loss did not improve from 0.00652\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0075 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00792: val_loss did not improve from 0.00652\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00793: val_loss did not improve from 0.00652\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00794: val_loss did not improve from 0.00652\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0074 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00795: val_loss did not improve from 0.00652\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00796: val_loss did not improve from 0.00652\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0064 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00797: val_loss improved from 0.00652 to 0.00638, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0067 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00798: val_loss did not improve from 0.00638\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00799: val_loss did not improve from 0.00638\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00800: val_loss did not improve from 0.00638\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0077 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00801: val_loss did not improve from 0.00638\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0061 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00802: val_loss improved from 0.00638 to 0.00614, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 3s 290ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00803: val_loss did not improve from 0.00614\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00804: val_loss did not improve from 0.00614\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0065 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00805: val_loss did not improve from 0.00614\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0082 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00806: val_loss did not improve from 0.00614\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00807: val_loss did not improve from 0.00614\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00808: val_loss did not improve from 0.00614\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0073 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00809: val_loss did not improve from 0.00614\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00810: val_loss improved from 0.00614 to 0.00607, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0067 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00811: val_loss did not improve from 0.00607\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00812: val_loss did not improve from 0.00607\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00813: val_loss did not improve from 0.00607\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0062 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00814: val_loss did not improve from 0.00607\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0076 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00815: val_loss did not improve from 0.00607\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0078 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00816: val_loss did not improve from 0.00607\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00817: val_loss did not improve from 0.00607\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0075 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00818: val_loss did not improve from 0.00607\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00819: val_loss did not improve from 0.00607\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00820: val_loss did not improve from 0.00607\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0072 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00821: val_loss did not improve from 0.00607\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00822: val_loss did not improve from 0.00607\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0072 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00823: val_loss did not improve from 0.00607\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0063 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00824: val_loss did not improve from 0.00607\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0064 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00825: val_loss did not improve from 0.00607\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0074 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00826: val_loss did not improve from 0.00607\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00827: val_loss did not improve from 0.00607\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00828: val_loss did not improve from 0.00607\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00829: val_loss did not improve from 0.00607\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0065 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00830: val_loss did not improve from 0.00607\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00831: val_loss did not improve from 0.00607\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0064 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00832: val_loss did not improve from 0.00607\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0076 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00833: val_loss did not improve from 0.00607\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00834: val_loss did not improve from 0.00607\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00835: val_loss did not improve from 0.00607\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0069 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00836: val_loss did not improve from 0.00607\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0077 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00837: val_loss did not improve from 0.00607\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0067 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00838: val_loss did not improve from 0.00607\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0070 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00839: val_loss did not improve from 0.00607\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00840: val_loss did not improve from 0.00607\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00841: val_loss did not improve from 0.00607\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0069 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00842: val_loss did not improve from 0.00607\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0068 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00843: val_loss did not improve from 0.00607\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0079 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00844: val_loss did not improve from 0.00607\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00845: val_loss did not improve from 0.00607\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0065 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00846: val_loss did not improve from 0.00607\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0069 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00847: val_loss did not improve from 0.00607\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00848: val_loss did not improve from 0.00607\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0068 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00849: val_loss did not improve from 0.00607\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00850: val_loss did not improve from 0.00607\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00851: val_loss did not improve from 0.00607\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00852: val_loss did not improve from 0.00607\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00853: val_loss did not improve from 0.00607\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00854: val_loss did not improve from 0.00607\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0067 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00855: val_loss did not improve from 0.00607\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0059 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00856: val_loss improved from 0.00607 to 0.00587, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00857: val_loss did not improve from 0.00587\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00858: val_loss did not improve from 0.00587\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0060 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00859: val_loss did not improve from 0.00587\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0061 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00860: val_loss did not improve from 0.00587\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0063 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00861: val_loss did not improve from 0.00587\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0058 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00862: val_loss improved from 0.00587 to 0.00575, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0064 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00863: val_loss did not improve from 0.00575\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00864: val_loss did not improve from 0.00575\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0062 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00865: val_loss did not improve from 0.00575\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00866: val_loss did not improve from 0.00575\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0059 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00867: val_loss did not improve from 0.00575\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0069 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00868: val_loss did not improve from 0.00575\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00869: val_loss did not improve from 0.00575\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0055 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00870: val_loss improved from 0.00575 to 0.00550, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00871: val_loss did not improve from 0.00550\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0051 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00872: val_loss improved from 0.00550 to 0.00508, saving model to /content/DeepPCB-master/PCBDatamodel.h5\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0067 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00873: val_loss did not improve from 0.00508\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0062 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00874: val_loss did not improve from 0.00508\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00875: val_loss did not improve from 0.00508\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0062 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00876: val_loss did not improve from 0.00508\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0063 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00877: val_loss did not improve from 0.00508\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00878: val_loss did not improve from 0.00508\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00879: val_loss did not improve from 0.00508\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00880: val_loss did not improve from 0.00508\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00881: val_loss did not improve from 0.00508\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0071 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00882: val_loss did not improve from 0.00508\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00883: val_loss did not improve from 0.00508\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00884: val_loss did not improve from 0.00508\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0059 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00885: val_loss did not improve from 0.00508\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00886: val_loss did not improve from 0.00508\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00887: val_loss did not improve from 0.00508\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00888: val_loss did not improve from 0.00508\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00889: val_loss did not improve from 0.00508\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0075 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00890: val_loss did not improve from 0.00508\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0074 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00891: val_loss did not improve from 0.00508\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0073 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00892: val_loss did not improve from 0.00508\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00893: val_loss did not improve from 0.00508\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0073 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00894: val_loss did not improve from 0.00508\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00895: val_loss did not improve from 0.00508\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00896: val_loss did not improve from 0.00508\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0081 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00897: val_loss did not improve from 0.00508\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00898: val_loss did not improve from 0.00508\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00899: val_loss did not improve from 0.00508\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0070 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00900: val_loss did not improve from 0.00508\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0072 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00901: val_loss did not improve from 0.00508\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00902: val_loss did not improve from 0.00508\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00903: val_loss did not improve from 0.00508\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0068 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00904: val_loss did not improve from 0.00508\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0060 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00905: val_loss did not improve from 0.00508\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0059 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00906: val_loss did not improve from 0.00508\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00907: val_loss did not improve from 0.00508\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0071 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00908: val_loss did not improve from 0.00508\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0069 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00909: val_loss did not improve from 0.00508\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0060 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00910: val_loss did not improve from 0.00508\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0069 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00911: val_loss did not improve from 0.00508\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0057 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00912: val_loss did not improve from 0.00508\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0070 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00913: val_loss did not improve from 0.00508\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00914: val_loss did not improve from 0.00508\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0080 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00915: val_loss did not improve from 0.00508\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0074 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00916: val_loss did not improve from 0.00508\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0072 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00917: val_loss did not improve from 0.00508\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0065 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00918: val_loss did not improve from 0.00508\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0073 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00919: val_loss did not improve from 0.00508\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0058 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00920: val_loss did not improve from 0.00508\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0056 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00921: val_loss did not improve from 0.00508\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00922: val_loss did not improve from 0.00508\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0068 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00923: val_loss did not improve from 0.00508\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0060 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00924: val_loss did not improve from 0.00508\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00925: val_loss did not improve from 0.00508\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0061 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00926: val_loss did not improve from 0.00508\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0058 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00927: val_loss did not improve from 0.00508\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0058 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00928: val_loss did not improve from 0.00508\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00929: val_loss did not improve from 0.00508\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0059 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00930: val_loss did not improve from 0.00508\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00931: val_loss did not improve from 0.00508\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00932: val_loss did not improve from 0.00508\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0060 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00933: val_loss did not improve from 0.00508\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0061 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00934: val_loss did not improve from 0.00508\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00935: val_loss did not improve from 0.00508\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00936: val_loss did not improve from 0.00508\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00937: val_loss did not improve from 0.00508\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0074 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00938: val_loss did not improve from 0.00508\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0066 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00939: val_loss did not improve from 0.00508\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0066 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00940: val_loss did not improve from 0.00508\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0068 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00941: val_loss did not improve from 0.00508\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0059 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00942: val_loss did not improve from 0.00508\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0068 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00943: val_loss did not improve from 0.00508\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00944: val_loss did not improve from 0.00508\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00945: val_loss did not improve from 0.00508\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0060 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00946: val_loss did not improve from 0.00508\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0055 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00947: val_loss did not improve from 0.00508\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0061 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00948: val_loss did not improve from 0.00508\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0063 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00949: val_loss did not improve from 0.00508\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00950: val_loss did not improve from 0.00508\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0065 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00951: val_loss did not improve from 0.00508\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0058 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00952: val_loss did not improve from 0.00508\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00953: val_loss did not improve from 0.00508\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00954: val_loss did not improve from 0.00508\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0065 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00955: val_loss did not improve from 0.00508\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0069 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00956: val_loss did not improve from 0.00508\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0061 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00957: val_loss did not improve from 0.00508\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00958: val_loss did not improve from 0.00508\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0061 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00959: val_loss did not improve from 0.00508\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0082 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00960: val_loss did not improve from 0.00508\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0077 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00961: val_loss did not improve from 0.00508\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0062 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00962: val_loss did not improve from 0.00508\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0058 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00963: val_loss did not improve from 0.00508\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0062 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00964: val_loss did not improve from 0.00508\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00965: val_loss did not improve from 0.00508\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0068 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00966: val_loss did not improve from 0.00508\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0063 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00967: val_loss did not improve from 0.00508\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0059 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00968: val_loss did not improve from 0.00508\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0063 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00969: val_loss did not improve from 0.00508\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00970: val_loss did not improve from 0.00508\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0060 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00971: val_loss did not improve from 0.00508\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0053 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00972: val_loss did not improve from 0.00508\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0063 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00973: val_loss did not improve from 0.00508\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00974: val_loss did not improve from 0.00508\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0059 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00975: val_loss did not improve from 0.00508\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00976: val_loss did not improve from 0.00508\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0055 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00977: val_loss did not improve from 0.00508\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00978: val_loss did not improve from 0.00508\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00979: val_loss did not improve from 0.00508\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0063 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00980: val_loss did not improve from 0.00508\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0062 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00981: val_loss did not improve from 0.00508\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0062 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00982: val_loss did not improve from 0.00508\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00983: val_loss did not improve from 0.00508\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0063 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00984: val_loss did not improve from 0.00508\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00985: val_loss did not improve from 0.00508\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0051 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00986: val_loss did not improve from 0.00508\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0052 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00987: val_loss did not improve from 0.00508\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0054 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00988: val_loss did not improve from 0.00508\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0054 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00989: val_loss did not improve from 0.00508\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 3s 289ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0054 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00990: val_loss did not improve from 0.00508\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0058 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00991: val_loss did not improve from 0.00508\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0056 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 00992: val_loss did not improve from 0.00508\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0058 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00993: val_loss did not improve from 0.00508\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0052 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00994: val_loss did not improve from 0.00508\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 3s 288ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0059 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00995: val_loss did not improve from 0.00508\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0051 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00996: val_loss did not improve from 0.00508\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0053 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00997: val_loss did not improve from 0.00508\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0055 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00998: val_loss did not improve from 0.00508\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0060 - val_accuracy: 0.9965\n",
            "\n",
            "Epoch 00999: val_loss did not improve from 0.00508\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 3s 287ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0065 - val_accuracy: 0.9964\n",
            "\n",
            "Epoch 01000: val_loss did not improve from 0.00508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLmYl1dNmB_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5132e7bc-0e10-424e-acc6-6eec164dd5bc"
      },
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "NkkRRyY_ghiC",
        "outputId": "8ec91508-eec6-489a-d465-4293a0ff03cf"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD9wtWSeoKzV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "d87d9da3-e4fc-47fa-b308-2ba6e95e341b"
      },
      "source": [
        "out = model.predict(tf.reshape(defect_img[0],(-1,128,128,1)))\n",
        "\n",
        "out2 = np.argmax(out,axis=3)\n",
        "print(out2[0])\n",
        "plt.imshow(out2[0],cmap='gnuplot')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0e82777290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z18WBIfpDcc"
      },
      "source": [
        "img_arr_resized = cv2.resize(defect_img[0],(88,88))\n",
        "img_arr_resized = cv2.cvtColor(img_arr_resized,cv2.COLOR_GRAY2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUNDnGTEpElO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "aa0abeef-3893-47ad-d38c-c4879b55daec"
      },
      "source": [
        "plt.imshow(img_arr_resized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0e827490d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMBltAu6pFb6"
      },
      "source": [
        "pred = model.predict(tf.reshape(defect_img[0],(-1,128,128,1)))\n",
        "pred = np.argmax(pred,axis=3)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvD7U4cPpGYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b99ff061-8f38-49e6-fb80-25d2f4e81600"
      },
      "source": [
        "plt.imshow(pred,cmap='gnuplot')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0e826ce0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHUwHT1DpKON"
      },
      "source": [
        "new_pred = np.zeros((88,88,3),dtype=np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edtn7aEcpQ23"
      },
      "source": [
        "new_pred[pred==0] = img_arr_resized[pred==0]\n",
        "new_pred[pred==1] = [255,228,0] #open\n",
        "new_pred[pred==2] = [1,0,255] #short\n",
        "new_pred[pred==3] = [29,219,22] #mousebite\n",
        "new_pred[pred==4] = [255,0,0] #spur\n",
        "new_pred[pred==5] = [103,0,0] #copper\n",
        "new_pred[pred==6] = [255,0,127] #pin-hole"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP-PgOd6pTEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "2495976e-883e-47c2-eb25-4fd1e5715a14"
      },
      "source": [
        "plt.imshow(new_pred,cmap='gnuplot')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0efa0c4790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nysygoaBpUMi"
      },
      "source": [
        "blend_img1=Image.fromarray(img_arr_resized)\n",
        "blend_img2=Image.fromarray(new_pred)\n",
        "blend_img=Image.blend(blend_img1,blend_img2,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITGiI3HhpU5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "cd115009-cd5b-4b05-d768-450026dc7b10"
      },
      "source": [
        "legend1 = mpatches.Patch(color='#FFE400', label='open')\n",
        "legend2 = mpatches.Patch(color='#0100FF', label='short')\n",
        "legend3 = mpatches.Patch(color='#1DDB16', label='mousebite')\n",
        "legend4 = mpatches.Patch(color='#FF0000', label='spur')\n",
        "legend5 = mpatches.Patch(color='#670000', label='copper')\n",
        "legend6 = mpatches.Patch(color='#FF007F', label='pinhole')\n",
        "plt.legend(loc='lower left', handles=[legend1,legend2,legend3,legend4,legend5,legend6],mode = \"expand\", ncol = 3,fontsize=10)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(np.array(blend_img))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXAcZ5n/P90996EZaXRLPuRDie84TmwnjsnhhASSDRAIR0E2IQUL4Spq2QBVULthi2KrlhQLpIDdggU2S1hCAgSWDSzJL0sSJ04c28iJ7diObfmQZZ2j0dwzPd39+2PU7ZGsa6yRpRm9H0oxM9PT8/bx7fd9n/c5JMMwEAgE8x95rhsgEAimhxCrQFAmCLEKBGWCEKtAUCYIsQoEZYIQq0BQJtiK2ViSJGPMa2w2G4qi0NDQQCgUQpKk0rZwgRKJROjv7yeXy5HJZNA0rST79Xq9LF68GLfbXdJrZRgG6XSaXC5HNBqlv7+/ZG1eaBiGMe6FKUqsF3zZZiMQCOD3+7n//vt5//vfj9frpa6uDofDMZNdL2gMw+DQoUO88sornD17ll/+8pccPnwYwzDQdX1G+168eDEPPPAAbW1tXH755SxbtswS7UzEG4vF+MMf/sDBgwd5/fXXeeaZZ0gkEjNqq2A0MxKrrutkMhkURaG/v59Tp04RCoUIBoNCrDNk2bJlNDY2cuLECZ5//nkOHz5ckv0ODQ3x8ssvc+LECZxOJ0uXLkWW5Rn3stlslsOHD7Nz5056enrI5XJIkoRwuikdMxKrJEkoioLNZsPtduP3+/F4PMiymArPFFmWURRl1LksxY2fy+UYGhrCbreTSCTI5XLWNZwuhe3QNI1cLkcymSQajTI0NEQikZjxCEBwITMSq6IouN1ufD4fTU1NrFixAqfTKXrVEqPresnmf4lEgmPHjtHf38/WrVuJx+M4HA68Xi+KohS9v3Q6zdDQED09PZw8eZKjR4+Sy+XI5XKiVy0xMxIr5AWrKAoulwufz3dBbyC4eCRJQpIkq5fVdX3GAtA0jXg8DkA8HieRSGAYBm63e9zrNtHw2Jw/Z7NZYrEY0WiUWCwm5qmzyIyHwebNZP4rhFoaZFnGZrPh8XhYvHgx7e3thMNh+vr6ZiRYU6yqqvLKK69gGAZLlizhlltuoaamBsgLcbI5rK7rRCIRkskkR44c4bnnnqOvr4/Ozs6Lbpdgambcs44VrFi6KQ2mWF0uF01NTbS1tSFJEgMDAzMaEmuaRjKZJJ1O09HRQV9fH5s2beKaa66hpqbGehBMJlhd14nFYgwODnLw4EF++9vfMjAwQDQaveh2CabmosRqijMYDLJhwwbq6+tpbm4WQi0xpmB9Ph/BYLBka6OGYWAYBslkkqGhIU6fPs3LL7/MsWPHrM/NB+/Y3zMMA03T6O/vJxqNcuTIEeLx+JRrwT4c1OBG5vz+JEAaeW0U/Bcgi8YASTJM78EkAdW4CUgus6Fj9phHx2CIFDGy09rvfKJosZo3kM1mY/ny5Xz605+mvb2d6urqizJQCMbHHKm4XC6am5tJJpMMDAyUbJqh6zrhcJjh4WG6u7t5/fXXsdvtwOjRkvkazs9TDcNAVVVyuRypVIpIJIKmaZNagBdRxTYW4Sy45WRJQpYVMEA3Rs/HB0nyZ05yjvi0jkdGZpVcx5VyM5KRPz4MMMbINYPGLs5wkP7pnah5RFFilWUZt9uNw+HA6XRSU1PD4sWLaWtrm632LUgKnRQURcHr9RIIBPD5fDidTgBUVZ2xsUlVVVRVJZ1OE4lERn1WaH8YT6zF/rYLGzW4cWM//xuSjE22nd/vyP8wQEPHVoQ3rAR4cVAnefN99Ui/UTis13WdNDlcM5/9zQlFtToYDPJXf/VXLFq0iJaWFpqammhoaJittgkAt9vN+vXrWbJkCV6vF1mWCYfD7N+/n8HBwVn7XVOU4w27Z+rsIEkSEhIupwu3220NyXO5HLqhoxsXt0YrSzKKLON2uqmuqcZut+fbaUAylWSgf4CMqllD73KjKLH6/X5uvPFGrrjiCtauXSsMSpcAp9PJypUrrSFmKpXi7NmzdHZ2zqpYgXF70MLe9mIFK0kSsiRjt9vxer1omkY2m0XTNCSjcA57cft1uVzU19fjdrvzQ2HDIBKJEBmKIKnle78WJVaHw0FLSwtVVVWj5jSC2UeSJILBIEuXLkWSpPyNOAcUDiuLIUqGTiJ4cdBg+PDiyM950ykMPW+0MgyDCGkGpARhUqSNXJFt09HMtd9ojEwmY6k+Ho+j6doFc9hyoiix+nw+tmzZgsPhED3qJcQcwSxevJi6ujqOHDnCr3/96zlpy8X2pmeIMkCSatzcSBttOEin02SymQIDE5yQhnhVOUvayBHT00V1sZquoxoq8Xic02dOn+9MjPySlZpVz8+Ly5CiDUx+v3+22iIYh0LjjtPpxOl0EgwGqa6uprq62jISmRba+eril0UjS36+mEAlZeSFo+cMawnHAOJSlghpsmjoRYpKVTRSikoOHV01kM1Is5Gh8MXOhecL5WkWW+DU19fz8Y9/nNtvv52jR49y6NAhhoeHOXr0KNFoFF3X560jfRKVfUY3xwlz4cIK9BlJsloOneIszrps0LlkmOxig5phN6uOhvAlR3zUx1nCKUeEWMuEQoNOdXU1t99+O5qm8cILL2C32zl37hzd3d2W3+/FLK9cCrJoHCM88QYX2WRdMuhpiDO0OkNrt5+lnVV49Mq6vSvraCqcwiGxaeALhUKsXLmSUCiErusMDg5y9uxZurq6UFWVVCq1MDI2GKCHDdROjVg4wwl1iH4uDCpQ0YiQnoMGzhwh1jLFdJhYtmwZNTU1ZLNZbrrpJlKpFH/4wx/4wx/+QCwW4+zZswtDrDqoJ3LkujTOaSpDmeQo18bzGKSn6cI43yharOMNrYRl+NIy1ugUCATQNA2Px0M2m6WpqYn6+npcLhfpdJpkMkk2m0VV1Tlu+SVgxOU3a4OJx9QKDkrnGlt4PWbKZNdoRmIVIp177Ha7NZ91Op1omsYNN9xAW1sbyWSSc+fOkUgkOHToEEeOHAHOLwUVzmvnen471sFmvs65x2KOcCRJsgx7F9Nu8/gPHjw44TYzGgZPFfcomF3MeauZmcPhcGAYBqtXr2bVqlVkMhn6+vpIJBJ4vV7S6TSGYVgBF4UJ2C6VOCa6X8ZzsJnsxp8v952Z4VOWZXRdv+gMGaZY33rrrQm3KUqssViMF154gbq6OkKhEA6Hg6qqqqLy9whKy9gh2HhBAIqisHLlSstLyBRGYa96KXuxsT3oRG6rk7VrvogVsHpWM3ywGAqvmyRJvPrqqxNuKxVzkWpqaoy3v/3tbN26lauuuopAIMCyZcvwer1FNVBQesa7joVRMtlslmw2O+FoaK6HnPOxTdOhVO0293PTTTfxl7/8ZeZ5g7PZLD09Pdafqqo0Nzdjt9svyL00n558C4GJomPMa2I6zQvmN5PFhBcl1kwmw+HDhwmHw+zevZvly5cD0NraSk1NDdXV1UKkAsEsUZRYc7kcvb299PX1ARAOh7n++utxu9243W6CwSAgelWBYDaYUYxbNBrlL3/5C7t27aK7uxsQQhUIZosZmXH7+/t5+umnqa6upra2lk2bNpWqXQKBYAwXJVbTomhWDIN8L5tIJLDb7TidTtHDCgQl5qKHwWb85NDQEH19fRw6dIiXXnqJAwcOkEwmS9lGgUDADOesmqaRSqVIJBL09vZy8uRJq4KYQCAoLTOas8pyPumV2+2murqaxsZGampqRP5ggWAWmHEVOY/Hg8/no7Gxkba2Nvx+v5UsWiAQlI4Zpyc0s/M7nU7cbjcul0tkPRQIZoGS9Kx+v59QKERTUxN2u1049gsEs8CMxWqW0vB4PFbGeIFAUHqKEqvH42HNmjXW61AoxPr16wmFQrS3t5e8cQKB4DxFibWqqoqbb77Zet3a2sptt91GfX29NfTVdV30rgLBLFCUWO12O83NzdbrhoYGqqqq8Hq9VqCw8FwSCGaHosQaCAS4/fbbrddOp5Oqqirgwhw6AoGgtBQlVqfTKWqxCgRzhJhcCgRlghCrQFAmCLEKBGWCEKtAUCYsWL9AwzDAyksrYYxbF8W0coMwdAvmmgUr1kw8Tv/x46RjceIsIsGicQUbCMCKFeDxzEEjBYICFrRYT+/bx9DZHnq5jh5aMUaqbwOWbJcsgaYmIVbB3LNgxYphYGgaupZDJoqDcxiGbFXIlpCQALvmRDKqABGjK5hbFq5YR5DQCXAED90YMMptUpZk6mjCzjageq6bKljgLHixYhjYjGEUI2IJ1ay0JksyLmzILIC6poJ5z4IXq2EY+do9vb0YI0WcZFmmubmZhoaGuW6eQGAhxGoY9PT28sYbb6CPlOtTFAW73U59ff0ct04gOM+CF6skSXg9HkKhUL6w8MgQ2O12z3XTBIJRCLFKEosWLaK2thY4X23A4/GIkD/BvGLhilWSkBUFxW7HZ7fjG4nLtSpRm9vYbMJ9STAvWLBidfn9LN60ifopcke5AwGcogixYB6wYMXq8HppWbeOqQrKmz2sQDDXLFixSiPe+UKGgnJBhMgJBGWCEKtAUCYIsQoEZYIQq0BQJgixCgRlghCrQFAmCLEKBGWCEKtAUCYIsQoEZYIQq0BQJgixCgRlghCrQFAmCLEKBGWCEKtAUCYIsQoEZYIQq0BQJgixCgRlghCrQFAmCLEKBGWCEKtAUCYIsQoEZcKCzW64YMnlIJ0GXZ98O5sNXC6QxfN8viDEutAYGoK9e2F4ePLtmprgyivB57s07RJMiRDrQmGkLAipFJw4AX19BR+Nk+pcVWHtWpFXeR4hxLoQMHTQe0Drg9wgGKnRHxsGuVwOg3y5S0UMfeclQqwLAh1yb0F2N2RzoGdHfarpOulMBkPXcbpcyHY7GIboVecZQqwLBUPN96hG3rBkGAaapqHrOtlsllgshq7rBGQZu91eknKX4w6vR5ju/g3DIJVKkUqlpt54BFmWcTqdyLKMzWZDUZTJf8/QwUgDmfNvjdfmKX/ZCZJ73NpIk52L6SLEukAxDINoLEY0GmV4eJgTx4+Ty+VYv2EDK1euLGmvat6oZu3bYh4EhmHw5ptvsmfPHnK5nPX+ZPsJBAIsX74cn89HQ0MDoVBoil9RQX0dtBPTbte42FaA/QrAMe7HEwnWPC9T7n4mbRPMH6b15DYMzD7DMAzS6TSxWIxwOExXVxeqqtK2bNmoGrUz7RF0/XxPbv4rFzEn1nWdvr4+Dhw4gKqq1vuTibWurg6v10t1dTVVVVVTH4ORA+0cqEcu/IjzPerke5FA8oNNG3dLwzDGbcfYB9lkCLFWIJqmoWkauVyOWCyGqqaJDx4mEd6LcVaHPWAMGMSiUeKJBPF4nHQmg5bLcerUKXRdJ3rmDKd7e8l4POP+hnljNTc3s3r1apxOp3XjnT17lsOHD6OqqrWdrutomjbqu9PB7FkPHDhgfX+qffj9fvr6+vB4PNTW1hIMBqmqqmLRokV4PB6am5sJhUJ0dXWxe/du0qkwzaGDhPynsdvtuN1u7HY7odpafD4fai5HNpNBVVX6+vuJx2IYXPgg64/00zVwEk0bX1bTefD19/dP+JkQawVhPr1VVSWbzZJMJjlz5gyJ+DBnju+h++T/w+jS4P8BA/ntdV0f9e+bb77J0aNHOSHLPPPrXxOZQBSmWLZt28b9999PMBi09vHiiy/ys5/9jFgshs1mQ5Zlq01Wr13EnDWXy40aAk+FJEnWPFWWZWRZZsmSJezYsYOGhga2bduG1+vlwIEDPPzwwwwOdPG2zWlWt2fx+XzUj/TM69atw+fzkc1mGR4eJh6Ps+8vf6Grqwtd161Rg8lfDio8v8tGJjv+sU1HrPF4fMLPhFgrBPOm1jSNcDhMOBwmkUhw5swZkskoQ+FB0uk0ZHQYbUsZhSmMJDCcSjGR64QptoGBAc6cOUM0GrXEeu7cOSKRCPF4HEVRkGWZXC5HNpudYG+zTzgcpre3F13XOXXqFB6Ph9OnTxMOhxkeHiaRzJHJ6NgUhUQiAZJEJpvNnw9VRVVV6/zquk4ulxs1LDcMSCbyviaZWTpMIdYKIZfLMTg4SCqV4rnnnuO5554jmUzS39+PqqZoX3KO5YuMkhVxN3uJo0eP8uMf/xi73W717JFIhFQqdX79doL52qVkcHCQnTt34nA4eOmll/D5fITDYfr6+pBQMfT8UlUmk6G/v59EIkF4cJBAVRWpdJp4IkE6ncbr9VJXV0c8HicSiVi966VY5hJirRA0TSOVShGNRjlx4gSvvvoqiUSCoaEhdD1LlRPaWkGepmamK62hoSEikcj5740YkEwj0njDxbkglUrR1dUFXGjscbvAXFU25/rmklE6nSYzMl/VNM2a02az2ZIsbxWDEGuFEIlEePbZZzl16hT79u1jeHiYbDaLpmkYBpzpBlsHSFHyw+Ap6GfCkfKEFFo2x1qB5wOF7RvvMwMJDAMDyGka3d3dZLNZ/H4/9fX1aLrO8IhPtTkfNgwDQ9en/XCbCUKsFcLAwAC/+tWv2L17N5lMJj8/5fyNefwkdJ4h32VOw1Yzzc1G/Ubh6/kkUpNJ22SAoRvWeFZVVU6ePMmZM2dob2/nsssuQ5Ikes6dA/KOF4qiAJC7RMcrxFqGmAYOTdOIxWJEIhE6OzsZGhoimUyO9Kajbx5Nz/+ZSJI0p4Ia+/vmkHKu2mSuQBcObHMFxqRcLoeiKLjcbgKBAJAfWudUlWQqha5P31p9sQixliG5XM4ygjz//PP86U9/YnBwkBMnToyyUI5H4bJG4XzyUomk8PdNl0dzSDlXbZoIfWR4m0qlGAyHcbvdtLS0sHjxYssKnhyxuA8PD48S+mw8fIoW63g/fqkn2gsdTdNIJBJ5N8ETJ3jllVdIJBLEYrFp3RymOAopnM/NtkjM39d13bp3TLGChGGYEX3nPa6mR/HtzrcFJGkCV0BAzeVIpVIoikIwGMTv92MYeacSm6Kc96WWRo8UillLNpnMGCd61jIkGo3y5z//mePHj9PR0UEsFiObzU7L6ipJEna7HZvNRmNjI7W1tXi9Xurr65Ekib1793L48OGSCdZ0ihhrFTYfCqabna7reYON3ohhtIIhU5xYdeAMcHbabauurmbZsmX4fQr19SeBvnG3i8VinDhxAq/Xez4AQtOorq7G6XRavsc+XwabLYmsOFi8eDF+v5+6ujqam5sLHkYXUniuf/Ob30zYXiHWMmR4eJj//d//ZdeuXUX1qJDvwex2O06nk5UrV7Ju3Trq6+vZsGEDsiyTyWQ4fPhwSdpZ+GAwnQgKRVo43M2/NtCNFjCuw8BOcT1lDngB6J7290KhEFu3biUYcCKr6Xy87zhEo1GOHj2K2+3G7XajKAoOh4NQKITP5yMSiSDJMlVVw9hsWewOL5dffjmtra2sW7eOLVu2YLfbLzg3412zl156acL2FiXWZDJJR0eH9drlclFbW4vT6cThcOBwOKynhxgaT85EywfmcovZExVuV2hMCofDpFIpSwATYc4PTf9Yp9NJdXU1LpeL5cuXs2jRImpqaqipqUGWZZYtW8aGDRtK0rPKsozD4cBms6Fp2gXzaVOw54eMMon4ZUSji1Bzedc7VVUvOA+T/KL1u3a7HUVRqK2tpbq6etytlyxZwpIlS/D7HJBdBbnCe1YHPQZGKt8+WcblcuHxeLDb7dafYcj4A4vRqGPRkjjr1kWw2T2sWLGChoYGGhsbCQQC2GyjpTbRnNa0MI+HVMxF8fl8xvr1663XS5cu5a677qKlpYWWlhYaGxstk7YQ6+SMHQZKkoSqqnR3dxOLxchkMiSTyVFzyVdffZVnn32WaDTKqVOnRpz01QmNSoqi4PF4cDqd3HDDDWzbto1AIMCyZcvwer34fD68Xi92ux2v1wvAuXPnGBwcLNlxmsO/8ebCY63BhgEH3vCxd6+fwXCMffv2MTAwQDaTJZPJYEzaY6rAn4FduN0u6urq8Pv93H333dxyyy3j3o8ul4vq6moURQJ9GIxEQeNSkH0FcsdBkpBGjsXr9eJwOpHNdVa8pPSN5IwmhqMaA+EckiRbD0aPx4Pf75+2HrZt28bevXvH3bionjWRSPDKK69YryORCFu3brWe1mZUxGTj84rHtI5M4yFoaBq6YeRvhhGxmm5syWRy1PDWMAyOHTvGa6+9Zq2hmu8XUnjezSBst9ttRcfU1NRw+eWX45sgEZrf77+Yoy4Jum5gGNDXD3bHIF6vl2g0ipYbidZhtNGmULySJAMKkmTD4XDg8/kIBoO0t7ezdevWycPyrNDBgnNpJCA9CLkpHH0lDw7XMrBfRqgelhV/2KN3N4luZjRnDYfD/PnPf+bQoUNcc801qKqK3++nqakJp9M5k12XL7kcHD8OPT2TbqZpGoODg8QTCXqBE0BypGeNRqMkk0mi0egFYk2n09ZDcWxvNfZC19bWsmPHDpqamrj66qtpa2vD4/HgcIwfHD2fcDqdLF6UN9J0n+3mTNcZHHYHdXV1uFwu7A77qHmgLOs0Nrqpr1+Jx+OioaEBn8+XD6SfsuPI5XtQveCaGSroE4erzQUzFuv//d//4fF4kOV8119fX08oFFq4YlVVOHoU9u+fdDMtk6H/2DH6+/vZDzxjGERV1XLGj8fjViSLyXT9bM2bMxQK8Y53vINVq1bR2NhoWXzLYdTjdDhZvHgx9fX1qFmVs91ncblcLFq0iGAwiMfjsYbuAIpicMXGNtasieJ25y20DodjwvnqKAwVckdBLbxmxS4bzT5FidXj8bB69WrC4bAVcaBpGul02lr383q988Jxe07RdRjxIiq0fJqGEk3TyGQyxCIRokNDRAyDIcMgpmnE43EymYzlPF6MTcEMRwuFQoRCIVauXEltbS1VVVW4XK6ymp5IsmSNAHw+H9XV1ZY11uF04HK5cLlc1vEoioHfr1FdreByOay5+FjDzgQ/BnIVyA3FN1T2g+Qq/nsXQVFiXbJkCY888gjPPPMMzz//PENDQ7z11lskk0l6eno4duyYZdEU5HtCNZdD13XSqRTZbJZsNksikSCVSnH8+PH8eQOOGQZJ8t5J41mCp8KcnzocDm666Sbe+c53Ultby7p16wgGg9O7aecRiqLg8/nQdZ0lS5Zgs9mw2WwEggEcDgdV/qpRhhubDVqaAyxbpmGznTdyTmZdPY8jnzvJ1n4xLQU5cBHfK56ie9aNGzdy/PhxK82GJEn5YOVkMh/Em0iInnUEs0c1e1LTwT4ej+eHurEY8XicOBAHpp+/70JMsbpcLpqamli1ahVVVVUEg0HcbneJjmi2kaz/ypKEbM9HtXi9XoLBIJIs4XQ4UWx5r6HCpUKbDdzufAGBotMeSzJIQSBY0qMpNUU/bmVZprW1lauuuorOzk6OHDlipQ/JZDLoul5U2shKRlVVotEomUyGU6dOMTg4mHcOyGYty2+pCAaD3HjjjbS0tLB582YaGxtxOp1l16NOhCRJyJKcz0u2QDMaX5RYm5ub2bhxIw5Hfm7Q399PV1cXp0+fpqqqatTSwkJGHUlYFo/HOX78OKdPnwZGDEAl9sENBoPccMMNrF27lkWLFlFfX19UFsH5TKGj/0IVKlykNdjtdlNdXU1TUxNr166lurqarq4uenp6LINTMpm8YIJfLsaNUmEYBvo43kilFKnpJbN06VIaGxutYW+5WH2ng81mw+12k8vlrGmWzW7D4/UgS2ZWiso41sm4qJ61rq6OYDBIY2MjjY2NhMNhHnvsMX7729+iqir9/f1UVVVRU1NDVVVVxdw0xaLrOtmRrH6zMY+XZZlrr72WD37wg4RCIVatWkUgEChZRv35gtfnxelyEolEOHb8GMPDw6zMrcxbfG32EavxdAxJ5U3RYpUkCafTac2HdF0nFApZ61lmrtrh4eEJvWQqGQPyaT40DW3EeV1VVYxxxSphjAzs7IyfmcEANMZPGyJJEjU1NaxcuZJAIGCtP1YaNiVfAkNRFGsNOplKWqsOeeeIwjNUOQ+qQmZkfShcRzT/uru7efLJJ2lsbOTOO+/kbW97W6naWhbomsbAwACxEWf7k6dOkUqliMViY7ZUgFrASxNwHdIYsead6ZKovMkA4TG2YnOYayYnK6c11IvFdDc0DIP+vn40TaOqqooVy1fgcnnnmQtD6SmJqbDQ7a23t5c//vGPBAIBVq9ezfbt2yv+JipE13WGwmHOnTnD4OAgp06eJDMSSTMaBQghUUsdUHdBb5AXa5gU3cQmFGuh8aWSGWVYMvKpRQcHB6mvr6e1tRUD78RfrhBKJlbzX9NDZ7w8QOVM4egBRoc4GYbB4OAgx44dIxEO0338OIORCNF4nHOahjqSHqTwbOSlCl4kFCm/iK/YFCt8LRaNMRgeRDLGt39O5sBfiRgY2O12amtrsdls+fXpWHyKSJzKYsZiHSvUwgRT0ym2U06YDyE4Lw4z9nTfvn1885vf5GxXF+rQELlEworhNIwLbykfsB1YDig2BbfLjd/v5+qrr6altYWDBw7y8q6XYQJnsMKSF5V0jifD68uXtFCzKoePHObIkXwhKXNBp9LPwoxyMBXWVSm8ic3AXHOdr1JupkIfX/NhlB0psdDX18dbb71lJZKeiizn8/KaQ1mbzZb3gw1W4/a4pzxvlTRymQ6WC6Km43Lm/XHPjzsq4x6bjIvuWQ3DYHh4mI6ODnp7ezk3kk+1urraShXS1NRUMUKF82Lt6uripZdeYmhoiL6+PiKRCKdPnx6Vmb4Y8j7EKql0ip6envywemBwWss9hT1sJVM4GcgnJ5vDxswRFyVW88ZIJBIcPXqUM2fOMDAwgCRJ+P1+Vq1aRXNzM7W1tSVt7FxjCqOvr4/nnnuOrq4ujh8/Tnd394zEYs7zs9ksg4N5kQ4PD097bXa+JtUWlJaLEqtpPs9ms/T29nL27FlracLtdrNo0SIWLVpkJUMea5Qpd1RVJRKJMDiYr8w2U6EUzvWjsSi6oZNIJKa137Hhd5VGpdwzpWBGBqZYLEZHRwdvvvmm5bwfCoW47rrrWLly5ajg4EoimT5RcF0AAB1ISURBVEzS2dlJZ2fnlEm1p4NhGGg5jbSW5uzZs1aJxOn0rKYRy5xDCyqXizIwZTIZstks0WiUaDRq9ao2mw2Xy0UgECAQCEwzlrA8MAzDcm6IRqNWhbGL3h+gopFCRTIkZOR8vZVMFnON1cAgQ24C/6XK7nUmevAUVlA3g+3z89dCw+eF36uEc1WUWDVNIxKJsHv3bvbu3cupU6fo7e1F0zRqamoIBAI0Njbicrmw2WwVcYJMstksTz/9NM8++yxnz56ddgZA0yI+1ok/Q4799HKaYUBCMsxzZRT8N7/d4DiRrqZDhM2WTxBWaH2vVFRVJTIcIZPJ29Hr6+sJBoLYbflcTAZ5oeaDmipr6gVFilXXdeLxOPv37+e3v/0tw8PDDA0NoWkaHo+HhoYGqqurcTgcFXfj5HI5du/ezaOPPjptw8/YyBdzTdQwDFR0OonQeZHtMfetjJRvqLSH43jktJyVTA4DqoPV+Hy+C0ZwlTodKEqs8XicF198kaNHjxKJREin09aaaltbG+vXr6e9vX1UbpxKY6obwWazsXTpUurr67HZbDidTnRd5+zZs1ZF8FgsVpIonEo9x5DvRcPhcD6hgZE3oJlVyc0kB4ZukEqnkBUZr8eB1zdEMhnB6/VQX1+Py+UiGAxWTEBJUWLt6enhW9/6Fn19fQwMDKAoCl6vF6/Xy3XXXcddd92F3++3rMALEZfLxc0338z111+Px+MhGAySTqd5+umneeONN+jt7eXo0aMi9c0UpFIpDr15iIGBAdSsajmfJJIJqwK5w+5AkiVOnDiBLOvs3fcXqqoO0trazI4dO6ivr2f16tULU6yqqnLu3DmSySS6ruNyuayY1fr6eurr63E6nRVnWJoOZskGj8dDbW0tLS0teDweqqurSaVSNDU10dfXRzabxel0WmurFzNkk2XZyv/rcrnOG1oqCDM9UDweJ5vJks6k0TXd+ldzaOhmwVkJJClHJtPH8PAZbDbZyrRZCmv9fKFoA1MsFrPKti9ZsoR3v/vdtLS0WDGVlXrjmD7AE1FdXU17ezu1tbWsWbOGZcuWWQWgNE3j1ltv5aqrrmLPnj2k02nL++nC0LnJkSSJQCDA1q1baW5u5uqrrz6f+HpM8aNyRtd1stks6XQ6n2gulUY3dOsBl81myWmFQYU50ulhFGWQYLCKZDI5KiF6JVC0gSmVShEKhaitrWX58uXcdtttLFs206IB85dCp4PJ8Hq9tLW10djYSGtrq5VQ23xwBYP5zHm6rvPyyy+jKArDw8PTFmvh/NTtdrNq1Souu+wyli9fTlVVVcUkRjMxMKzKc9lslkw2M+rznJaDUTpUgSQQI5FIWMuLC1asfr+frVu30tjYSENDA21tbXi93oo2dKTTaXp7e4lEIgwPD0+4nc/nY9myZTQ3NxMIBCYMYggGg6xatYrq6moGBgYYGBiYsg2FxZ0AHA4Hzc3NLFu2jJqamoo+/4LzFCXWhoYGPve5zxEKhaipqbESp1Uy0WiU/fv309vbS88k9WtCoRDXXHMNixcvpqmpacKpQEtLCzfffDPd3d0cO3aM48ePT9kGMxOE2cO73W7WrFnDNddcY5U2FFQ+RYnVbrfT1NREMBi0EnOJG6U4Ct0Dp1u3xrQDeDweXK58OcOqqqpR+ZYqpXd12MHrBa/HwGZLI8tJJClFfog7mTEuR34oXLkUJVaHw8HSpUtHecxUmjFpLIFAgCuvvJJIJMKuXbsm3G5wcJBdu3Zx6tQprrvuOgKBgDVnLbT8vvnmm/zoRz+it7eXY8eOTfn7Zgyny+Xi2muv5dZbb6W+vr4i7QSSBEvbwOOFzs4E+1/fTzh8kFwuCgwzuVgNoG+KbcqbosRqs9kIhUKz1ZZ5iRlFZLpTTkQ8HufEiRMkEgnWrl2LruuWUOG8RfncuXO89NJL9PX1TWvZxswm6fF4WLVqFe9617vyBX0LSkdUCpIEtbX5P5stS1XVGRyOt1CUISRpqGI9k6ZLZZkQZ4Gx2RsnIpPJ0Nvbi6qqdHR0kMlkRrkbmj3rkSNHUFV1lMFoPMzhr9/vZ+PGjbS0tNDe3o7D4RCV5adBYUK5SkGIdRqYveJk4orH43R2dtLT00M8HmfPnj2jPje/e/LkyWlF65hpXmpqanjHO97Bpk2baGhosJwgKukmLDWVKFQQYp0W07nwZtkQwzAYGhoaZTwqFPnYAsljMZdpzIoGLS0t1NXVEQqF8Hq9CyLtqGB8hFinwXRy86qqytDQELIsE41GJ/QmSqfTqKp6gWDNYa/H48Fut3PjjTdy9913W0WRq6urLaOeEOv0qLTzJMQ6BYVDKvNvvOGwpmlWtoxEInFRvyHLMg6HA7fbzYoVK7jtttuoqqoqyXEsNCpNqCDEOm1kWWbp0qVs2bKFoaEhOjs7rSDoUuzb4XDg8/m4+uqraW1tZe3atRXnQjhbjC0lUmmFuUzE3TBNbDYba9euJZ1O89Zbb1lxlaXat8eTj8G844472Lx5M3V1dTidzpLsv5IZK1IzeEKIdQFjplltbGxkeHiYmpoaa+g7U9H6/X5aWlpoamqirq6OmpoaPB5PRd5w08Vut9PQ0MCiRYswDINIJDJq+mGz2azgfjM7iSnW1tZWqqur8fv9FfXAE2KdJoqisHz5cmpra2ltbbXSsO7du5ejR48CxacTMd0IN23axL333ktdXR0rV6606rksZLHW19fz0Y9+lKGhIX7xi1/w6KOPks1mrdQ4oVCIuro6K0yzubl5lFtmYaaISkGIdZqYtVCDwSCGYdDe3o7f7x/JUiAXnfnBHL4pikJzczPbtm0jFApVXPD+xeL1etm4cSOqqvLqq69e4NbqdrsJhUIsWbKE7du3s2LFiopdXzURYi0CU2BmOcumpibC4TCSJI0yOhWGtI0VsTl083g8rF271gog93g8C743nYzCUYssy6xatYqbb76ZlpYWgsFgRYvURIi1CMwbIhQKcfXVV5NOp9F1nZqaGo4ePUpPTw/ZbNYajplZ8gtvNIfDQSAQoK6ujjvuuIMtW7ZYUTTC+js55nlUFIUrr7yS+++/38qQUelCBSHWaVN4M5hLLZCPY21ubiadTrNixQqi0Sg2m80Sq+mmaP653W6CwSA1NTU0NjZSU1ODz+cTzg5F4nA4rDxUCwUh1ovEFOzq1atZvHgxsViMHTt2kM1mRwnP7F1zuRyapllOD06nk0WLFo3yTBKMjyi8lUeI9SIwhagoCrW1tdTW1pLL5Whra7OslYWeTmaCL03TrAz6Zh1b0yl/Icy5LpoxlZIlScIY+Z9u6AWbSdbnlYgQa4kwxTdeJXLDMKxhsaIolkDF0HcaSKA0KDg32LGnFKrTNXhkL2l/io7MPhQtfwvLyDTbm2lQGue4wbOHEGuJKJzHCkqHJIGtWca52Y496aAt3EaVFiBZleSV1C4kJf+ws0k2trCVeqVhVOHlSkKItUSIHnIWUSQku4ShGOS0HGpOJaerqIaar74HYIBOZVc5EGIVlA1qVqWvr59YKk5ddEx6oQXwrCwbseYtgmNrb44ukzgaCUnC+hOUOxK6rpFKp9AT+khZDMO6tgvhEpeNWLNZOHYMwmZZ1CmujgQ0t8CSJSC898ocI/+wzmkaiXicdDRdsoincqJsxJpOw8EDcOTIxD2l2b9K5LfZsgUWtQqxVgpaTiMRSyFFpBlVnS9X5r1Ys8kk6WiUeFTHSIJDM85b+6SxA2ED8x0JSMd89PT4cLllAgEQxtrywwCMpI7Wr6MP6RiqjoSCV/JSr9SjKPlbWJEUPLJ3bhs7y8xrsRqGQeTsWU688grpeBpnxGDxyGeF5nmJQrGan0oMnVjL/w5sorpGZtt10Fi5S3CViwG5Uxrp5zNkEln0qIEiS7Q5lnOj9+aCXFcSPtlXscs2MM/FCvmeNXruHJlEAtkwMAtGmN5B1qWRzveokiSBJJNILKIvZaDpoGYvdcsF4zGR2+CE7+sGWlxH69PRMyPX3CHhk3zUyw04lPxwaSEsnc17sZqcr8mpMRQOc66nB13XsdlsKLKM2+PB5/Plo1qqqnA6XbS0wrI28PmhauEWY593mL6+Zv1VTdPIZDLjlmfM5XJEo9ELvp9MJhkcHMTtduP3+xdExFLZHKF5cbPZLOfOnaOjo4NcLofT6bTKejQ2NeHxeHC7XDhdLlpbYOW1oNhB+MnPH8w433Q6TSQSQVVVotEo2eyFwx9N0yyxFvpbm2L1+/243W4h1vmElRhLUXCNlJrUNA2Xy4XNZiMQDOIdqbImj5h/JSkvUmENLi2FIX+FAQhj35toaGpWkR8cHOT48eNWJfjxlmM0TaOnp2fUMNlMpN7Z2UltbS3V1dWjci1V6pC4rMTqcDhQbDZaWlrw+/1APr2HfSR5lhlqNlGCbUHp0DQNTdOs1DSAVcZSUZQJr4Gu61Y1846ODn75y18yPDxMb2/vhPmWh4aGyOVyo4p8vfHGG1Z6nebm5gWRX3nei1WSQFZAtoFNkpF1Ca/sxu5UkCVpZAiUvzEKn6eSPPI3N82uGAp7NF3XLdFks1lyuZwVRQT5qgRjwwALc/oqimINf9PpNP39/XR2djI0NERPT8+0k6MbhkE0GqWrq4tgMDjizVT5zHuxVtXB8qtBy4JuyGAY6LoNTc8HOdrt8rjzUQkILAZJDIFnjNljdnZ28sILLxCNRhkeHiaRSIwbaG8KU1EUAoEALpeL5cuXs3HjRhKJBH/84x85duwYb731FmfPniWdTo87X50Mc95bbKK6cmZei1UCfCHweUyfYDMKWWY6TZecI5sKZoRZrf3EiRM8+eSTdHd309PTQyQSmfA7Znxva2srgUCAG264gebmZoaGhvjNb37Diy++OG5CuelipswRYp1HSLIX7K1IRrG+oBIo1Qi1zgxd14lGo8RiMQYHBxkeHiYej0+41GJiDn8TiQSSJHH69Gn27dtHNBolHA5P+t2LoVKNSoXMb7FKEiit4AxC0bGKEkhuQIyDZ4KmaZw8eZITJ05w4MABurq6CIfDk84TCwtIDw4OEolECIfDvPbaa2iaxsDAwKVqfkUxv8UKILlAcc11KxYshmGQSqVG9aiZTGbaCcxUVUVVVVKplBDpDJn/YhXMOeb80JwjTiXUwkRxhWuwgpkhxCqYFNMIZIq1WNHNpkgXWopSYX0RTMnYYtKCuUGIVTApYx0bzDVUIdpLjxCrYEoURbEqCVRVVeH3+4VL5xwg5qyCSVEUhaVLl+L3+1m6dCkrVqxgcHCQ3/3ud+zdu3dO27bQhuVCrIJJURSFxsZGamtrWbFiBVdeeSUDAwMcPHhwzsW60JCKsaZdddVVxp49e0a9p6oqXV1dCzKB1UJhbHiaruskEokZZxic7lLQWCRJsnyPbTZbWQafu1wuWltbL5hOXHXVVezZs2fc4cKMj7Crq8saIi2kIclCYTwhGYYxbaGNd0+YSy6JRIJYLHZRyy+2kbBIh8NBVVXVqJt+vt+HhmEwODhIV1cXbW1t0/7ejMWaTqeFUCuYia7reD3ZeKIbO68sDFxXVdUq5lUsZq9ajsW9zILc/f39RX2vJGOHcjtZgtlhuveBuZ3L5UKW5XEr701nH6ZQlTJMBXIxmimvgb6gYjBD6Eq9BFTJHUfpxXquEfTe0u1PboCmntLt7yLZ1LmWfq24Yctk1Cl17G07ULL9zQY33HADDz/8MFddddWo9//7v/+bQ4cO8eUvf5mnnnqK9vZ2Vq9ePem+vtjYSLS3dPdFVUMD/9wz9/fFpaT0ThGlFOps7O8iKaVQZ2N/l5I777yTL3/5ywA89dRTHDp0aMrvlFKos7G/2aKUcbsV4cH0rW99i7Vr17J27Vq+/e1vc/LkSS6//HI+/OEPs2rVKt73vveRTCYB2Lt3L9dffz2bNm3i1ltv5dy5c0C+F/nSl77E5s2baW9v58UXX5zLQ7KO4b777qO9vZ0Pf/jDPPvss2zbto2VK1eye/duwuEw7373u1m/fj1bt27l9ddfB+Chhx7i4Ycftva1du1aTp48SSKR4Pbbb2fDhg2sXbuWxx9/HJj4nAD853/+J1dccQVr165l9+7dAPz0pz/lM5/5DC+//DK/+93vePDBB7niiis4fvw4x48f57bbbmPTpk1s376dw4cPX8KzdiGPPvoo69evZ8OGDdxzzz2cPHmSm266ifXr17Njxw5Onz4NwH333ccnP/lJrrrqKtrb2/n9738P5I/1Xe96FzfccAMrV67ka1/7mrXvn/3sZ2zevJkrrriCT3ziE5YwfT4fX/jCF9iwYQO7du0q2bGUvVj37t3LT37yE1599VVeeeUVfvjDHzI0NMSRI0f41Kc+xZtvvklVVRXf//73UVWVz372szz55JPs3buX+++/n6985SvWvnK5HLt37+bb3/72qIsyVxw7dowvfOELHD58mMOHD/Pzn/+cnTt38vDDD/ONb3yDf/iHf2Djxo28/vrrfOMb3+Cv//qvJ93fH//4R5qbm9m/fz8HDhzgtttum/KcJJNJOjo6+P73v8/9998/an/XXnstd955J9/85jfp6Ohg+fLl/M3f/A2PPPIIe/fu5eGHH+ZTn/rUrJyb6XDw4EG+/vWv89xzz7F//36+853v8NnPfpZ7772X119/nQ9/+MN87nOfs7Y/efIku3fv5n/+53/45Cc/afkO7N69m1/96le8/vrrPPHEE+zZs4c333yTxx9/nJdeeomOjg4UReGxxx4DIJFIsGXLFvbv3891111XsuMpewPTzp07ec973oPXmy9KdNddd/Hiiy+yaNEitm3bBsBHPvIRvvvd73Lbbbdx4MABbrnlFiA/RGlqarL2dddddwGwadMmTp48eWkPZBza2tpYt24dAGvWrGHHjh1IksS6des4efIkp06d4le/+hUAN910E4ODgxdkry9k3bp1fOELX+BLX/oSd9xxB9u3b+fAgQOTnpMPfehDALztbW8jGo1OmncpHo/z8ssvc/fdd1vvzWVpxueee467776b2tpaAGpqati1axe//vWvAbjnnnv44he/aG3//ve/H1mWWblyJcuWLbNGBbfccguhUL5481133cXOnTux2Wzs3buXq6++GoBUKkV9fT2QX1Z673vfW/LjKXuxTsRYq6CZzX3NmjUTDk3MRNGKopDL5Wa9jVNRmLhalmXrtSzL5HK5CS2pNpttVCIxs4dob29n3759PP3003z1q19lx44dvOc975n0nIx3HidC13WCwSAdHR3TO8B5xkTHOtG9dO+99/JP//RPF+zH5XLNynJS2Q+Dt2/fzlNPPUUymSSRSPCb3/yG7du3c/r0aesG/PnPf851113HZZddRn9/v/W+qqocPHhwLps/I7Zv324Nvf785z9TW1tLVVUVS5cuZd++fQDs27ePzs5OALq7u/F4PHzkIx/hwQcfZN++fVOeE3Neu3PnTgKBAIHA6KJBfr+fWCwGQFVVFW1tbTzxxBNA3gFi//79s3gGJuemm27iiSeeYHAwX4E7HA5z7bXX8otf/AKAxx57jO3bt1vbP/HEE+i6zvHjxzlx4gSXXXYZAM888wzhcJhUKsVTTz3Ftm3b2LFjB08++SR9fX3Wvk+dOjWrx1P6nlVuKP3SzSRceeWV3HfffWzevBmAj33sY1RXV3PZZZfxve99j/vvv5/Vq1fzwAMP4HA4ePLJJ/nc5z7H8PAwuVyOz3/+86xZs2bKZtQpdSVfupkpDz30EPfffz/r16/H4/HwH//xHwC8973v5dFHH2XNmjVs2bKF9vZ2AN544w0efPBBq2rBD37wgynPicvlYuPGjaiqyo9//OML2vDBD36Qj3/843z3u9/lySef5LHHHuOBBx7g61//Oqqq8sEPfpANGzZQ1dBQ8qWbqVizZg1f+cpXuP7661EUhY0bN/LII4/w0Y9+lG9+85vU1dXxk5/8xNp+8eLFbN68mWg0yr/+67/icuVzf23evJn3vve9dHV18ZGPfMRayvr617/O29/+dnRdx263873vfY8lS5aU7BgvoND9a6q/TZs2GWM5dOjQBe/NNZ2dncaaNWvmuhmCMuLee+81nnjiiQve/8lPfmJ8+tOfnpXfHE87IxobV39lPwwWCBYKFWlgWrp0KQcOzG/vIMH84qc//em47993333cd999l7QtEyF6VoGgTBBiFQjKBCFWgaBMEGIVCMqEkhuYmhqhlAERDQ1wrshIqKVLl7Jnzx7LzaxYOjo66O7u5p3vfOf5Nxtn4cAWUohX4zehd3rFkqdFgxd6Hryor37sYx/jb//2bycN67vvvvu44447eN/73jetfZ48eZI77rhjVg2bJe9ZSx25dKkjoXK5HB0dHTz99NOz25BLfGBz7j5ZSqHOcH8/+tGPpoy/nY+U/TB4orCvRx55hCuvvJJ169ZZDtmThZTdc889bNu2jXvuuYe///u/5/HHH+eKK66w9jcfjmvp0qV88YtfZN26dWzevJljx44B+V7gySeftL7r8/mAvAvi9u3bufPOO8vy5pyKwvo7hX8mE4VK3nDDDZhZOn0+H1/5ylfYsGEDW7dupbfgIfrCCy9w7bXXsmzZMuv8GobBgw8+yNq1a1m3bt2494emaTz44INcffXVrF+/nn/7t38ryfGWvVjHC/sCqK2tZd++fTzwwANWbOdkIWWHDh3i2Wef5b/+67/4x3/8Rz7wgQ/Q0dHBBz7wgXl1XIFAgDfeeIPPfOYzfP7zn59yP/v27eM73/kOR48ene0mX3Li8TipVGrS6ufjhUoWkkgk2Lp1K/v37+dtb3sbP/zhD63Pzp07x86dO/n9739vBdv/+te/pqOjg/379/Pss8/y4IMPjor/Bfj3f/93AoEAr732Gq+99ho//OEPLf/smVD2Yl23bh3PPPMMX/rSl3jxxRctR/Pxwt127tzJPffcA1wYUnbnnXfidrsv/QFMwETHZYasfehDH5pWYPPmzZuLSndZTqiqSi6XmzQ74thQyZ07d4763OFwcMcddwAXhka++93vRpZlVq9ebfW4O3fu5EMf+hCKotDQ0MD111/Pa6+9Nmqff/rTn3j00Ue54oor2LJlC4ODg7z11lszPt6y92AaL+wLig93M+Nh5wsTHVdhuJb5/wtD4nRdJ5vNWtvMt+MqJalUCofDgcfjmTAkbaoQP7vdbr039l4pDFGc7IEwFsMweOSRR7j11lun/Z3pUPY963hhXxMxUUjZWArDvuaKiY7LnCM9/vjjXHPNNUDe+m2Wsvjd736Hqqpz0+hLTCKRIJ1OTzoMHi9UciZs376dxx9/HE3T6O/v54UXXrAivkxuvfVWfvCDH1jX4ejRoyQSMzewlVys04hcKun+3njjDSsPzte+9jW++tWvTrjtQw89xN69e1m/fj1f/vKXrZCysdx4440cOnRotIHpEh/YRMc1NDTE+vXr+c53vsO//Mu/APDxj3+c559/3sr5My9704bStkkNOUcZlCaqH2uGSq5atYqhoSEeeOCBGf3ue97zHiun00033cQ///M/09jYOGqbj33sY6xevZorr7yStWvX8olPfKIk1vgZ17p58803WbVq1YwbIpiama4fzwcKrbYDAwN0d3dfVAZAh8OB3W7H7XbT2NhoxZ4WcinWPmfCeNqZrNZN2Q+DBeVLMR2FoAIMTAuJ+ZDErZyotFDJkvSs4gkpEBTHxWhmxmJ1uVwMDg4KwQoE08QYKfk43jx7MmY8DG5tbaWrq6vo8nWChYn5UDcMg3g8TiQSmVHJR7vdTjQaLXmBq9nGLKZcDDMWq91ur1gPGUHpMZ02VFXlRz/6EQ899FDRBZUlSaK1tZXW1lbWrVvH3/3d37Fy5cpZbPX8QFiDBYIyQYhVICgThFgFgjKhKA8mSZL6gdmtESAQLGyWGIYxbrmGosQqEAjmDjEMFgjKBCFWgaBMEGIVCMoEIVaBoEwQYhUIygQhVoGgTBBiFQjKBCFWgaBMEGIVCMqE/w9JQxfc2LWc+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t53PYcKfvsCK",
        "outputId": "f11f5e72-5824-402c-ae7c-41d12e6523f8"
      },
      "source": [
        "len(defectlog)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWihHkZ9pWI3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "c91b1f47415e43308fe8319315ccf07c",
            "ed6107f01b30435885fe0be911750009",
            "a29c9aa28441439db87a2a6995ced6a7",
            "dfec29aea15e40bb8f79bec51af53e4d",
            "dde41332a90441ceb6b44e0ffa438a3e",
            "5949218be01947c3a757c50b3d78b191",
            "db1ce35a04074dc6aacf4d75cad25b93",
            "cdca6d991daa455581f4e93fc66f7a1c"
          ]
        },
        "outputId": "533babe0-3067-4f80-ba7a-72adedb6e74f"
      },
      "source": [
        "log_df = pd.DataFrame(columns=['0','1','2','3','4','5','6'])\n",
        "i=0\n",
        "for log in tqdm(defectlog,total=len(defectlog)):\n",
        "    temp_df = pd.read_csv(log,sep=' ' ,names=['x1', 'y1', 'x2', 'y2', 'defect'], header=None)\n",
        "    temp = np.zeros(7,dtype=int)\n",
        "    for t in temp_df['defect']:\n",
        "        temp[t]+=1\n",
        "    log_df.loc[i,:] = temp\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c91b1f47415e43308fe8319315ccf07c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EScto2iPgarP"
      },
      "source": [
        "dataset2 = tf.data.Dataset.from_tensor_slices((defect_img,log_df.values.astype(np.int)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUIWX9pgb2w"
      },
      "source": [
        "n=1500\n",
        "dataset2 = dataset2.shuffle(n)\n",
        "train_dataset2 = dataset2.take(int(n*0.8)).batch(100)\n",
        "test_dataset2 = dataset2.skip(int(n*0.8)).batch(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-EyGv1Anhsw"
      },
      "source": [
        "load_model = tf.keras.models.Model(\n",
        "    [model.inputs],\n",
        "    [model.layers[16].output]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzFSRRyGnjlO"
      },
      "source": [
        "for layer in load_model.layers:\n",
        "    layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NY9Fffnnk4v"
      },
      "source": [
        "x = load_model.output #25 25 256\n",
        "x = keras.layers.MaxPooling2D((3, 3), strides=2)(x) #12 12 256\n",
        "x_l = keras.layers.BatchNormalization()(x)\n",
        "x_l = keras.layers.Activation('relu')(x_l)\n",
        "x_l = keras.layers.Conv2D(filters=256,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\n",
        "x_l = keras.layers.BatchNormalization()(x_l)\n",
        "x_l = keras.layers.Activation('relu')(x_l)\n",
        "x_l = keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\n",
        "x = keras.layers.Concatenate()([x, x_l]) #12 12 320\n",
        "\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Activation('relu')(x)\n",
        "x = keras.layers.Conv2D(filters=160,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #6 6 160\n",
        "\n",
        "x_l = keras.layers.BatchNormalization()(x)\n",
        "x_l = keras.layers.Activation('relu')(x_l)\n",
        "x_l = keras.layers.Conv2D(filters=160,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\n",
        "x_l = keras.layers.BatchNormalization()(x_l)\n",
        "x_l = keras.layers.Activation('relu')(x_l)\n",
        "x_l = keras.layers.Conv2D(filters=40,kernel_size=3,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\n",
        "x = keras.layers.Concatenate()([x, x_l]) #6 6 200\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(x) #1*1*200\n",
        "outputs = keras.layers.Dense(7,activation='linear')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8uRMfjAnnOH",
        "outputId": "15c084b7-ddd5-4834-81c8-2444f5c65480"
      },
      "source": [
        "model2 = keras.Model(load_model.inputs, outputs)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling_1 (Rescaling)         (None, 128, 128, 1)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "random_flip_1 (RandomFlip)      (None, 128, 128, 1)  0           rescaling_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 126, 126, 64) 640         random_flip_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 126, 126, 64) 0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 124, 124, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 124, 124, 64) 0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 60, 60, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 60, 60, 128)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 58, 58, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 58, 58, 128)  0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 29, 29, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 27, 27, 256)  295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 27, 27, 256)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 256)  590080      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 256)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 256)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 12, 12, 256)  1024        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 12, 12, 256)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 12, 12, 256)  65792       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 12, 256)  1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 12, 12, 256)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 12, 12, 64)   147520      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 12, 12, 320)  0           max_pooling2d_4[0][0]            \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 12, 320)  1280        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 320)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 12, 12, 160)  51360       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 160)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 6, 6, 160)    640         max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 6, 6, 160)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 6, 6, 160)    25760       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 6, 6, 160)    640         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 6, 6, 160)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 6, 6, 40)     57640       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 6, 6, 200)    0           max_pooling2d_5[0][0]            \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            1407        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 1,498,343\n",
            "Trainable params: 351,783\n",
            "Non-trainable params: 1,146,560\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELnqwdUnnosN"
      },
      "source": [
        "model2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A6sq7RjnrLk",
        "outputId": "cf628f8a-1842-410a-bfb2-910e87213eda"
      },
      "source": [
        "# callback2 = tf.keras.callbacks.ModelCheckpoint(path+'model2.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='loss', save_freq='epoch',)\n",
        "# history2 = model2.fit(train_dataset2,epochs=1000,validation_data=test_dataset2,callbacks=[callback2])\n",
        "history2 = model2.fit(train_dataset2,epochs=500,validation_data=test_dataset2,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 2s 73ms/step - loss: 1.1675 - accuracy: 0.1742 - val_loss: 31.9147 - val_accuracy: 0.0467\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.5395 - accuracy: 0.3308 - val_loss: 11.0474 - val_accuracy: 0.1067\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.4722 - accuracy: 0.2917 - val_loss: 4.9983 - val_accuracy: 0.1567\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.4363 - accuracy: 0.3208 - val_loss: 1.9859 - val_accuracy: 0.1233\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.4188 - accuracy: 0.3442 - val_loss: 1.3428 - val_accuracy: 0.1700\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.4152 - accuracy: 0.3958 - val_loss: 1.0224 - val_accuracy: 0.1300\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.4148 - accuracy: 0.3567 - val_loss: 0.7961 - val_accuracy: 0.2233\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.4024 - accuracy: 0.3908 - val_loss: 0.6260 - val_accuracy: 0.2367\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3857 - accuracy: 0.4033 - val_loss: 0.5650 - val_accuracy: 0.2000\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3704 - accuracy: 0.3967 - val_loss: 0.4568 - val_accuracy: 0.1567\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3731 - accuracy: 0.4058 - val_loss: 0.4305 - val_accuracy: 0.3100\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3645 - accuracy: 0.3900 - val_loss: 0.4320 - val_accuracy: 0.3067\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3513 - accuracy: 0.4375 - val_loss: 0.3570 - val_accuracy: 0.3700\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3425 - accuracy: 0.4200 - val_loss: 0.4208 - val_accuracy: 0.4800\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3472 - accuracy: 0.4075 - val_loss: 0.4236 - val_accuracy: 0.4400\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3397 - accuracy: 0.4333 - val_loss: 0.5701 - val_accuracy: 0.4167\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3225 - accuracy: 0.4517 - val_loss: 0.4033 - val_accuracy: 0.4767\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3288 - accuracy: 0.4617 - val_loss: 0.4071 - val_accuracy: 0.5200\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.3178 - accuracy: 0.4233 - val_loss: 0.3900 - val_accuracy: 0.4900\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.3180 - accuracy: 0.4850 - val_loss: 0.4435 - val_accuracy: 0.5700\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.3209 - accuracy: 0.4417 - val_loss: 0.3501 - val_accuracy: 0.5667\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2944 - accuracy: 0.4783 - val_loss: 0.3536 - val_accuracy: 0.5367\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2894 - accuracy: 0.4775 - val_loss: 0.4215 - val_accuracy: 0.3767\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2865 - accuracy: 0.4933 - val_loss: 0.3729 - val_accuracy: 0.4433\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2829 - accuracy: 0.4750 - val_loss: 0.3392 - val_accuracy: 0.6133\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2744 - accuracy: 0.5033 - val_loss: 0.3746 - val_accuracy: 0.6267\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2675 - accuracy: 0.5042 - val_loss: 0.3586 - val_accuracy: 0.4000\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2689 - accuracy: 0.5125 - val_loss: 0.4177 - val_accuracy: 0.4300\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2679 - accuracy: 0.4975 - val_loss: 0.3371 - val_accuracy: 0.5100\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2525 - accuracy: 0.5392 - val_loss: 0.3192 - val_accuracy: 0.6067\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2517 - accuracy: 0.5225 - val_loss: 0.3682 - val_accuracy: 0.5033\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2453 - accuracy: 0.5292 - val_loss: 0.3458 - val_accuracy: 0.4333\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2284 - accuracy: 0.5325 - val_loss: 0.4936 - val_accuracy: 0.6033\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2368 - accuracy: 0.5508 - val_loss: 0.3432 - val_accuracy: 0.5500\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2181 - accuracy: 0.5508 - val_loss: 0.4398 - val_accuracy: 0.6133\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2240 - accuracy: 0.5517 - val_loss: 0.3805 - val_accuracy: 0.6167\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2071 - accuracy: 0.5725 - val_loss: 0.4799 - val_accuracy: 0.3667\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2089 - accuracy: 0.5608 - val_loss: 0.2960 - val_accuracy: 0.4067\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1992 - accuracy: 0.5733 - val_loss: 0.2891 - val_accuracy: 0.4167\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1912 - accuracy: 0.5967 - val_loss: 0.3119 - val_accuracy: 0.4200\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2056 - accuracy: 0.5558 - val_loss: 0.2531 - val_accuracy: 0.5400\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1816 - accuracy: 0.6025 - val_loss: 0.2722 - val_accuracy: 0.3833\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1648 - accuracy: 0.5808 - val_loss: 0.2307 - val_accuracy: 0.4333\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1728 - accuracy: 0.5925 - val_loss: 0.2697 - val_accuracy: 0.5967\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1609 - accuracy: 0.6225 - val_loss: 0.3607 - val_accuracy: 0.3900\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1652 - accuracy: 0.5800 - val_loss: 0.3477 - val_accuracy: 0.5167\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1621 - accuracy: 0.5950 - val_loss: 0.2077 - val_accuracy: 0.6433\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1481 - accuracy: 0.6175 - val_loss: 0.1993 - val_accuracy: 0.5400\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1463 - accuracy: 0.6133 - val_loss: 0.4720 - val_accuracy: 0.3533\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1469 - accuracy: 0.6133 - val_loss: 0.3891 - val_accuracy: 0.6200\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1536 - accuracy: 0.6250 - val_loss: 0.2842 - val_accuracy: 0.4867\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1362 - accuracy: 0.6342 - val_loss: 0.2441 - val_accuracy: 0.5800\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1292 - accuracy: 0.6117 - val_loss: 0.2350 - val_accuracy: 0.4567\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1230 - accuracy: 0.6242 - val_loss: 0.2548 - val_accuracy: 0.4367\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1243 - accuracy: 0.6425 - val_loss: 0.2004 - val_accuracy: 0.5200\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1228 - accuracy: 0.6375 - val_loss: 0.4089 - val_accuracy: 0.4167\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1252 - accuracy: 0.6217 - val_loss: 0.1421 - val_accuracy: 0.7567\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1147 - accuracy: 0.6475 - val_loss: 0.2081 - val_accuracy: 0.5133\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1078 - accuracy: 0.6392 - val_loss: 0.1501 - val_accuracy: 0.6600\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1063 - accuracy: 0.6458 - val_loss: 0.1090 - val_accuracy: 0.6833\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1055 - accuracy: 0.6667 - val_loss: 0.1520 - val_accuracy: 0.6967\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1106 - accuracy: 0.6650 - val_loss: 0.2306 - val_accuracy: 0.3867\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1042 - accuracy: 0.6808 - val_loss: 0.1342 - val_accuracy: 0.6300\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1047 - accuracy: 0.6350 - val_loss: 0.2036 - val_accuracy: 0.4567\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1064 - accuracy: 0.6625 - val_loss: 0.2574 - val_accuracy: 0.4433\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0945 - accuracy: 0.6592 - val_loss: 0.1220 - val_accuracy: 0.5433\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0816 - accuracy: 0.6583 - val_loss: 0.1272 - val_accuracy: 0.4767\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0859 - accuracy: 0.6633 - val_loss: 0.0954 - val_accuracy: 0.8033\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0897 - accuracy: 0.6625 - val_loss: 0.2031 - val_accuracy: 0.4533\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0766 - accuracy: 0.6867 - val_loss: 0.1222 - val_accuracy: 0.5967\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0824 - accuracy: 0.6583 - val_loss: 0.1535 - val_accuracy: 0.5700\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0796 - accuracy: 0.6642 - val_loss: 0.2546 - val_accuracy: 0.5333\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0749 - accuracy: 0.6800 - val_loss: 0.0906 - val_accuracy: 0.6100\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0758 - accuracy: 0.6358 - val_loss: 0.1879 - val_accuracy: 0.4933\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0741 - accuracy: 0.6733 - val_loss: 0.2133 - val_accuracy: 0.5933\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0747 - accuracy: 0.6775 - val_loss: 0.1194 - val_accuracy: 0.5600\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0723 - accuracy: 0.6542 - val_loss: 0.1108 - val_accuracy: 0.8200\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0691 - accuracy: 0.6633 - val_loss: 0.0746 - val_accuracy: 0.6700\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0692 - accuracy: 0.6767 - val_loss: 0.1414 - val_accuracy: 0.5667\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0814 - accuracy: 0.6358 - val_loss: 0.2148 - val_accuracy: 0.7600\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0860 - accuracy: 0.6342 - val_loss: 0.1652 - val_accuracy: 0.5800\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0710 - accuracy: 0.6667 - val_loss: 0.1262 - val_accuracy: 0.5967\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0689 - accuracy: 0.6658 - val_loss: 0.1721 - val_accuracy: 0.6333\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0650 - accuracy: 0.6767 - val_loss: 0.0778 - val_accuracy: 0.6333\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0676 - accuracy: 0.6683 - val_loss: 0.2440 - val_accuracy: 0.3500\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0669 - accuracy: 0.6675 - val_loss: 0.1085 - val_accuracy: 0.5567\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0776 - accuracy: 0.6383 - val_loss: 0.1579 - val_accuracy: 0.4667\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0749 - accuracy: 0.6375 - val_loss: 0.1988 - val_accuracy: 0.5367\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0637 - accuracy: 0.6750 - val_loss: 0.1317 - val_accuracy: 0.8600\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0656 - accuracy: 0.6750 - val_loss: 0.0946 - val_accuracy: 0.8867\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0795 - accuracy: 0.6633 - val_loss: 0.2434 - val_accuracy: 0.6067\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0552 - accuracy: 0.6675 - val_loss: 0.0861 - val_accuracy: 0.5733\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0509 - accuracy: 0.6742 - val_loss: 0.2090 - val_accuracy: 0.5100\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0546 - accuracy: 0.6608 - val_loss: 0.1099 - val_accuracy: 0.6067\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0477 - accuracy: 0.6733 - val_loss: 0.0929 - val_accuracy: 0.8633\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0514 - accuracy: 0.6808 - val_loss: 0.1775 - val_accuracy: 0.4467\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0616 - accuracy: 0.6450 - val_loss: 0.2357 - val_accuracy: 0.5500\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0663 - accuracy: 0.6633 - val_loss: 0.0837 - val_accuracy: 0.5667\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0460 - accuracy: 0.6492 - val_loss: 0.1140 - val_accuracy: 0.6833\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0541 - accuracy: 0.6900 - val_loss: 0.3703 - val_accuracy: 0.2900\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0750 - accuracy: 0.6317 - val_loss: 0.3117 - val_accuracy: 0.4667\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0896 - accuracy: 0.6308 - val_loss: 0.1460 - val_accuracy: 0.5200\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0826 - accuracy: 0.6517 - val_loss: 0.3389 - val_accuracy: 0.7267\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0741 - accuracy: 0.6400 - val_loss: 0.1105 - val_accuracy: 0.4933\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0598 - accuracy: 0.6433 - val_loss: 0.0606 - val_accuracy: 0.6900\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0534 - accuracy: 0.6667 - val_loss: 0.1012 - val_accuracy: 0.5167\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0588 - accuracy: 0.6808 - val_loss: 0.0968 - val_accuracy: 0.7400\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0586 - accuracy: 0.6292 - val_loss: 0.1657 - val_accuracy: 0.5700\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0571 - accuracy: 0.6483 - val_loss: 0.0795 - val_accuracy: 0.7300\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0435 - accuracy: 0.6600 - val_loss: 0.1871 - val_accuracy: 0.4700\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0419 - accuracy: 0.6875 - val_loss: 0.0773 - val_accuracy: 0.6267\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0511 - accuracy: 0.6733 - val_loss: 0.1969 - val_accuracy: 0.4900\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0484 - accuracy: 0.6425 - val_loss: 0.1275 - val_accuracy: 0.4667\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0409 - accuracy: 0.6783 - val_loss: 0.0769 - val_accuracy: 0.6067\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0386 - accuracy: 0.6575 - val_loss: 0.1146 - val_accuracy: 0.8067\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0515 - accuracy: 0.6617 - val_loss: 0.1082 - val_accuracy: 0.6300\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0459 - accuracy: 0.6392 - val_loss: 0.1440 - val_accuracy: 0.7500\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0379 - accuracy: 0.6417 - val_loss: 0.1031 - val_accuracy: 0.6267\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0420 - accuracy: 0.6542 - val_loss: 0.0462 - val_accuracy: 0.6867\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0413 - accuracy: 0.6425 - val_loss: 0.0686 - val_accuracy: 0.7600\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0362 - accuracy: 0.6867 - val_loss: 0.0544 - val_accuracy: 0.7533\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0378 - accuracy: 0.6967 - val_loss: 0.1386 - val_accuracy: 0.4833\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0484 - accuracy: 0.6192 - val_loss: 0.1498 - val_accuracy: 0.5333\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0437 - accuracy: 0.6658 - val_loss: 0.1160 - val_accuracy: 0.5100\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0341 - accuracy: 0.6492 - val_loss: 0.0519 - val_accuracy: 0.6500\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0349 - accuracy: 0.6633 - val_loss: 0.0866 - val_accuracy: 0.5867\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0401 - accuracy: 0.6700 - val_loss: 0.1606 - val_accuracy: 0.4567\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0472 - accuracy: 0.6383 - val_loss: 0.2999 - val_accuracy: 0.5200\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0471 - accuracy: 0.6242 - val_loss: 0.1348 - val_accuracy: 0.5200\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0403 - accuracy: 0.6367 - val_loss: 0.0946 - val_accuracy: 0.8700\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0345 - accuracy: 0.6550 - val_loss: 0.0615 - val_accuracy: 0.7900\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0363 - accuracy: 0.6642 - val_loss: 0.0331 - val_accuracy: 0.5900\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0360 - accuracy: 0.6483 - val_loss: 0.1410 - val_accuracy: 0.6000\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0324 - accuracy: 0.6333 - val_loss: 0.1017 - val_accuracy: 0.5433\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0444 - accuracy: 0.6575 - val_loss: 0.0762 - val_accuracy: 0.5600\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0356 - accuracy: 0.6225 - val_loss: 0.0356 - val_accuracy: 0.6200\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0322 - accuracy: 0.6917 - val_loss: 0.0450 - val_accuracy: 0.6533\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0311 - accuracy: 0.6533 - val_loss: 0.0383 - val_accuracy: 0.7167\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0314 - accuracy: 0.6658 - val_loss: 0.0920 - val_accuracy: 0.8767\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0295 - accuracy: 0.6733 - val_loss: 0.0600 - val_accuracy: 0.5433\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0391 - accuracy: 0.6667 - val_loss: 0.1941 - val_accuracy: 0.4233\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0357 - accuracy: 0.6592 - val_loss: 0.1159 - val_accuracy: 0.6767\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0380 - accuracy: 0.6408 - val_loss: 0.1036 - val_accuracy: 0.6233\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0421 - accuracy: 0.6608 - val_loss: 0.1444 - val_accuracy: 0.6367\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0411 - accuracy: 0.6725 - val_loss: 0.1257 - val_accuracy: 0.8267\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0382 - accuracy: 0.6842 - val_loss: 0.1759 - val_accuracy: 0.8167\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0316 - accuracy: 0.6933 - val_loss: 0.0893 - val_accuracy: 0.5733\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0278 - accuracy: 0.6508 - val_loss: 0.0341 - val_accuracy: 0.6967\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0337 - accuracy: 0.6442 - val_loss: 0.2367 - val_accuracy: 0.5833\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0481 - accuracy: 0.6325 - val_loss: 0.2890 - val_accuracy: 0.5133\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0473 - accuracy: 0.6592 - val_loss: 0.0837 - val_accuracy: 0.5567\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0332 - accuracy: 0.6508 - val_loss: 0.0370 - val_accuracy: 0.6000\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0311 - accuracy: 0.6667 - val_loss: 0.1622 - val_accuracy: 0.4600\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0323 - accuracy: 0.6783 - val_loss: 0.0335 - val_accuracy: 0.6433\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0302 - accuracy: 0.6567 - val_loss: 0.1217 - val_accuracy: 0.5333\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0400 - accuracy: 0.6658 - val_loss: 0.1332 - val_accuracy: 0.4933\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0431 - accuracy: 0.6558 - val_loss: 0.1618 - val_accuracy: 0.5733\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0358 - accuracy: 0.6683 - val_loss: 0.1432 - val_accuracy: 0.6100\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0309 - accuracy: 0.6308 - val_loss: 0.0869 - val_accuracy: 0.6100\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0279 - accuracy: 0.6692 - val_loss: 0.0945 - val_accuracy: 0.4967\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0278 - accuracy: 0.6567 - val_loss: 0.0458 - val_accuracy: 0.7000\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0265 - accuracy: 0.6708 - val_loss: 0.0668 - val_accuracy: 0.9367\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0284 - accuracy: 0.6467 - val_loss: 0.0485 - val_accuracy: 0.5700\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0269 - accuracy: 0.6550 - val_loss: 0.0825 - val_accuracy: 0.5533\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0304 - accuracy: 0.6650 - val_loss: 0.1086 - val_accuracy: 0.7067\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0291 - accuracy: 0.6508 - val_loss: 0.0588 - val_accuracy: 0.5533\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0374 - accuracy: 0.6533 - val_loss: 0.0473 - val_accuracy: 0.4967\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0310 - accuracy: 0.6783 - val_loss: 0.1564 - val_accuracy: 0.4300\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0350 - accuracy: 0.6842 - val_loss: 0.1210 - val_accuracy: 0.5467\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0332 - accuracy: 0.6450 - val_loss: 0.1247 - val_accuracy: 0.7400\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0281 - accuracy: 0.6392 - val_loss: 0.0821 - val_accuracy: 0.6100\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0352 - accuracy: 0.6667 - val_loss: 0.1187 - val_accuracy: 0.4800\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0320 - accuracy: 0.6542 - val_loss: 0.1400 - val_accuracy: 0.9000\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0352 - accuracy: 0.6800 - val_loss: 0.1012 - val_accuracy: 0.7833\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0354 - accuracy: 0.6542 - val_loss: 0.0852 - val_accuracy: 0.5067\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0305 - accuracy: 0.6442 - val_loss: 0.0430 - val_accuracy: 0.8167\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0259 - accuracy: 0.6717 - val_loss: 0.0536 - val_accuracy: 0.5933\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0241 - accuracy: 0.6867 - val_loss: 0.0509 - val_accuracy: 0.5500\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0229 - accuracy: 0.7083 - val_loss: 0.0281 - val_accuracy: 0.5333\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0236 - accuracy: 0.6592 - val_loss: 0.0477 - val_accuracy: 0.5767\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0291 - accuracy: 0.6400 - val_loss: 0.0286 - val_accuracy: 0.6133\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0283 - accuracy: 0.6467 - val_loss: 0.0473 - val_accuracy: 0.7433\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0268 - accuracy: 0.6708 - val_loss: 0.0301 - val_accuracy: 0.5900\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0276 - accuracy: 0.6675 - val_loss: 0.1202 - val_accuracy: 0.5033\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0261 - accuracy: 0.6558 - val_loss: 0.0461 - val_accuracy: 0.5533\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0220 - accuracy: 0.6583 - val_loss: 0.0465 - val_accuracy: 0.6733\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0210 - accuracy: 0.6550 - val_loss: 0.1835 - val_accuracy: 0.7800\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0264 - accuracy: 0.6925 - val_loss: 0.0861 - val_accuracy: 0.5133\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0324 - accuracy: 0.6592 - val_loss: 0.2193 - val_accuracy: 0.3433\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0335 - accuracy: 0.6592 - val_loss: 0.1063 - val_accuracy: 0.5533\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0325 - accuracy: 0.6717 - val_loss: 0.0862 - val_accuracy: 0.5767\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0339 - accuracy: 0.6217 - val_loss: 0.0472 - val_accuracy: 0.7667\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0346 - accuracy: 0.6600 - val_loss: 0.0629 - val_accuracy: 0.8933\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0294 - accuracy: 0.6725 - val_loss: 0.0869 - val_accuracy: 0.5733\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0245 - accuracy: 0.6658 - val_loss: 0.0364 - val_accuracy: 0.6467\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0326 - accuracy: 0.6625 - val_loss: 0.1441 - val_accuracy: 0.6533\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0274 - accuracy: 0.6492 - val_loss: 0.0964 - val_accuracy: 0.6767\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0333 - accuracy: 0.6317 - val_loss: 0.0620 - val_accuracy: 0.5800\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0345 - accuracy: 0.6467 - val_loss: 0.0976 - val_accuracy: 0.6133\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0327 - accuracy: 0.6558 - val_loss: 0.0381 - val_accuracy: 0.6967\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0261 - accuracy: 0.6708 - val_loss: 0.0337 - val_accuracy: 0.6567\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0234 - accuracy: 0.6383 - val_loss: 0.1197 - val_accuracy: 0.6433\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0251 - accuracy: 0.6558 - val_loss: 0.0460 - val_accuracy: 0.7000\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0219 - accuracy: 0.6683 - val_loss: 0.0162 - val_accuracy: 0.5900\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0202 - accuracy: 0.6458 - val_loss: 0.0730 - val_accuracy: 0.7167\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0239 - accuracy: 0.6517 - val_loss: 0.0916 - val_accuracy: 0.5267\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0243 - accuracy: 0.6850 - val_loss: 0.0126 - val_accuracy: 0.6700\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0250 - accuracy: 0.6408 - val_loss: 0.0690 - val_accuracy: 0.6033\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0201 - accuracy: 0.6475 - val_loss: 0.0595 - val_accuracy: 0.5967\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0363 - accuracy: 0.6267 - val_loss: 0.0653 - val_accuracy: 0.6133\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0337 - accuracy: 0.6650 - val_loss: 0.0570 - val_accuracy: 0.5767\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0269 - accuracy: 0.6300 - val_loss: 0.0792 - val_accuracy: 0.5933\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0343 - accuracy: 0.6492 - val_loss: 0.1593 - val_accuracy: 0.5833\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0435 - accuracy: 0.6650 - val_loss: 0.1344 - val_accuracy: 0.5300\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0368 - accuracy: 0.6492 - val_loss: 0.1686 - val_accuracy: 0.7933\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0326 - accuracy: 0.6342 - val_loss: 0.0520 - val_accuracy: 0.8400\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0281 - accuracy: 0.6758 - val_loss: 0.0888 - val_accuracy: 0.6300\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0262 - accuracy: 0.6600 - val_loss: 0.0458 - val_accuracy: 0.5567\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0238 - accuracy: 0.6700 - val_loss: 0.0499 - val_accuracy: 0.7700\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0227 - accuracy: 0.6783 - val_loss: 0.0788 - val_accuracy: 0.8100\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0232 - accuracy: 0.6750 - val_loss: 0.1329 - val_accuracy: 0.5967\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0318 - accuracy: 0.6542 - val_loss: 0.1054 - val_accuracy: 0.8233\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0359 - accuracy: 0.6517 - val_loss: 0.1670 - val_accuracy: 0.5733\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0281 - accuracy: 0.6858 - val_loss: 0.0751 - val_accuracy: 0.4967\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0217 - accuracy: 0.6542 - val_loss: 0.0450 - val_accuracy: 0.5700\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0246 - accuracy: 0.6700 - val_loss: 0.0604 - val_accuracy: 0.6533\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0276 - accuracy: 0.6592 - val_loss: 0.0781 - val_accuracy: 0.7133\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0265 - accuracy: 0.6600 - val_loss: 0.0615 - val_accuracy: 0.5500\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0240 - accuracy: 0.6458 - val_loss: 0.0264 - val_accuracy: 0.6633\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0251 - accuracy: 0.6467 - val_loss: 0.0704 - val_accuracy: 0.7133\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0261 - accuracy: 0.6642 - val_loss: 0.0386 - val_accuracy: 0.6000\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0263 - accuracy: 0.6442 - val_loss: 0.1759 - val_accuracy: 0.5233\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0302 - accuracy: 0.6458 - val_loss: 0.1113 - val_accuracy: 0.8533\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0344 - accuracy: 0.6525 - val_loss: 0.0814 - val_accuracy: 0.6633\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0315 - accuracy: 0.6508 - val_loss: 0.1024 - val_accuracy: 0.4900\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0249 - accuracy: 0.6275 - val_loss: 0.0246 - val_accuracy: 0.8300\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0224 - accuracy: 0.6833 - val_loss: 0.0339 - val_accuracy: 0.6100\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0355 - accuracy: 0.6708 - val_loss: 0.1663 - val_accuracy: 0.3967\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0298 - accuracy: 0.6625 - val_loss: 0.1073 - val_accuracy: 0.6900\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0281 - accuracy: 0.6583 - val_loss: 0.0932 - val_accuracy: 0.8700\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0291 - accuracy: 0.6958 - val_loss: 0.0570 - val_accuracy: 0.8167\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0273 - accuracy: 0.6342 - val_loss: 0.1321 - val_accuracy: 0.7567\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0300 - accuracy: 0.6733 - val_loss: 0.0636 - val_accuracy: 0.6733\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0280 - accuracy: 0.6567 - val_loss: 0.0420 - val_accuracy: 0.6200\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0249 - accuracy: 0.6600 - val_loss: 0.1176 - val_accuracy: 0.8300\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0226 - accuracy: 0.6750 - val_loss: 0.0531 - val_accuracy: 0.5833\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0216 - accuracy: 0.6533 - val_loss: 0.0640 - val_accuracy: 0.6000\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0217 - accuracy: 0.6775 - val_loss: 0.0602 - val_accuracy: 0.7233\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0211 - accuracy: 0.6425 - val_loss: 0.0979 - val_accuracy: 0.5433\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0230 - accuracy: 0.6508 - val_loss: 0.0816 - val_accuracy: 0.7667\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0299 - accuracy: 0.6733 - val_loss: 0.1624 - val_accuracy: 0.4167\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0334 - accuracy: 0.6408 - val_loss: 0.1942 - val_accuracy: 0.6467\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0345 - accuracy: 0.6458 - val_loss: 0.1104 - val_accuracy: 0.7800\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0272 - accuracy: 0.6558 - val_loss: 0.1228 - val_accuracy: 0.4500\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0286 - accuracy: 0.6775 - val_loss: 0.2307 - val_accuracy: 0.4333\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0261 - accuracy: 0.6592 - val_loss: 0.0908 - val_accuracy: 0.6233\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0187 - accuracy: 0.6417 - val_loss: 0.0485 - val_accuracy: 0.8800\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0186 - accuracy: 0.6708 - val_loss: 0.0352 - val_accuracy: 0.5900\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0256 - accuracy: 0.6400 - val_loss: 0.0837 - val_accuracy: 0.5600\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0302 - accuracy: 0.6767 - val_loss: 0.0466 - val_accuracy: 0.7033\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0317 - accuracy: 0.6750 - val_loss: 0.0669 - val_accuracy: 0.8333\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0343 - accuracy: 0.6533 - val_loss: 0.1454 - val_accuracy: 0.4667\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0329 - accuracy: 0.6825 - val_loss: 0.1400 - val_accuracy: 0.4300\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0365 - accuracy: 0.6608 - val_loss: 0.1265 - val_accuracy: 0.5233\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0305 - accuracy: 0.6575 - val_loss: 0.0858 - val_accuracy: 0.9100\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0272 - accuracy: 0.6942 - val_loss: 0.1212 - val_accuracy: 0.5167\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0326 - accuracy: 0.6508 - val_loss: 0.1043 - val_accuracy: 0.5267\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0211 - accuracy: 0.6492 - val_loss: 0.0495 - val_accuracy: 0.5333\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0213 - accuracy: 0.6792 - val_loss: 0.0481 - val_accuracy: 0.4833\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0322 - accuracy: 0.6350 - val_loss: 0.0803 - val_accuracy: 0.7100\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0319 - accuracy: 0.6450 - val_loss: 0.0890 - val_accuracy: 0.5500\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0249 - accuracy: 0.6533 - val_loss: 0.0672 - val_accuracy: 0.8767\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0223 - accuracy: 0.6592 - val_loss: 0.0216 - val_accuracy: 0.6967\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0219 - accuracy: 0.6617 - val_loss: 0.0545 - val_accuracy: 0.5600\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0254 - accuracy: 0.6367 - val_loss: 0.1118 - val_accuracy: 0.6333\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0230 - accuracy: 0.6683 - val_loss: 0.0415 - val_accuracy: 0.5567\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0198 - accuracy: 0.6558 - val_loss: 0.0338 - val_accuracy: 0.5167\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0221 - accuracy: 0.6325 - val_loss: 0.0953 - val_accuracy: 0.5500\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0284 - accuracy: 0.6558 - val_loss: 0.0843 - val_accuracy: 0.6067\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0310 - accuracy: 0.6300 - val_loss: 0.1029 - val_accuracy: 0.5967\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0306 - accuracy: 0.6625 - val_loss: 0.0928 - val_accuracy: 0.6367\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0287 - accuracy: 0.6417 - val_loss: 0.1477 - val_accuracy: 0.5300\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0254 - accuracy: 0.6808 - val_loss: 0.0557 - val_accuracy: 0.5933\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0293 - accuracy: 0.6583 - val_loss: 0.0536 - val_accuracy: 0.6133\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0295 - accuracy: 0.6633 - val_loss: 0.0886 - val_accuracy: 0.5667\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0222 - accuracy: 0.6400 - val_loss: 0.0295 - val_accuracy: 0.6000\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0252 - accuracy: 0.6567 - val_loss: 0.1003 - val_accuracy: 0.5467\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0261 - accuracy: 0.6783 - val_loss: 0.1090 - val_accuracy: 0.5333\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0267 - accuracy: 0.6392 - val_loss: 0.0554 - val_accuracy: 0.8533\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0246 - accuracy: 0.6600 - val_loss: 0.0808 - val_accuracy: 0.5033\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0208 - accuracy: 0.6625 - val_loss: 0.0376 - val_accuracy: 0.6500\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0240 - accuracy: 0.6417 - val_loss: 0.1725 - val_accuracy: 0.6400\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0279 - accuracy: 0.6792 - val_loss: 0.0352 - val_accuracy: 0.5567\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6433 - val_loss: 0.1139 - val_accuracy: 0.6767\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0260 - accuracy: 0.6450 - val_loss: 0.0734 - val_accuracy: 0.7700\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0239 - accuracy: 0.6542 - val_loss: 0.0439 - val_accuracy: 0.5267\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0239 - accuracy: 0.6633 - val_loss: 0.0915 - val_accuracy: 0.5533\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0226 - accuracy: 0.6575 - val_loss: 0.0655 - val_accuracy: 0.7467\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0241 - accuracy: 0.6617 - val_loss: 0.0295 - val_accuracy: 0.7200\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0198 - accuracy: 0.6692 - val_loss: 0.0641 - val_accuracy: 0.5800\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0230 - accuracy: 0.6600 - val_loss: 0.0858 - val_accuracy: 0.5500\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0214 - accuracy: 0.6458 - val_loss: 0.0379 - val_accuracy: 0.6467\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0273 - accuracy: 0.6242 - val_loss: 0.0739 - val_accuracy: 0.5267\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0236 - accuracy: 0.6467 - val_loss: 0.0853 - val_accuracy: 0.9300\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0241 - accuracy: 0.6817 - val_loss: 0.0960 - val_accuracy: 0.5433\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0231 - accuracy: 0.6592 - val_loss: 0.0401 - val_accuracy: 0.6300\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0238 - accuracy: 0.6367 - val_loss: 0.0991 - val_accuracy: 0.8300\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0324 - accuracy: 0.6425 - val_loss: 0.0414 - val_accuracy: 0.4800\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0259 - accuracy: 0.6558 - val_loss: 0.0359 - val_accuracy: 0.4667\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0218 - accuracy: 0.6508 - val_loss: 0.0680 - val_accuracy: 0.5467\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6417 - val_loss: 0.0562 - val_accuracy: 0.8067\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0223 - accuracy: 0.6492 - val_loss: 0.0896 - val_accuracy: 0.5567\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0220 - accuracy: 0.6583 - val_loss: 0.0240 - val_accuracy: 0.6967\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0250 - accuracy: 0.6350 - val_loss: 0.0490 - val_accuracy: 0.8967\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6358 - val_loss: 0.0759 - val_accuracy: 0.7033\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0221 - accuracy: 0.6633 - val_loss: 0.0163 - val_accuracy: 0.5867\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0169 - accuracy: 0.6525 - val_loss: 0.0455 - val_accuracy: 0.8600\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0212 - accuracy: 0.6733 - val_loss: 0.0579 - val_accuracy: 0.6833\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0188 - accuracy: 0.6750 - val_loss: 0.0738 - val_accuracy: 0.5133\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0212 - accuracy: 0.6475 - val_loss: 0.0453 - val_accuracy: 0.6200\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0259 - accuracy: 0.6500 - val_loss: 0.0706 - val_accuracy: 0.6233\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0214 - accuracy: 0.6517 - val_loss: 0.0532 - val_accuracy: 0.7767\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0207 - accuracy: 0.6542 - val_loss: 0.0676 - val_accuracy: 0.6267\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0226 - accuracy: 0.6342 - val_loss: 0.0425 - val_accuracy: 0.5400\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0232 - accuracy: 0.6550 - val_loss: 0.0734 - val_accuracy: 0.5867\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0241 - accuracy: 0.6608 - val_loss: 0.0793 - val_accuracy: 0.5300\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0365 - accuracy: 0.6492 - val_loss: 0.1293 - val_accuracy: 0.8200\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0380 - accuracy: 0.6792 - val_loss: 0.2729 - val_accuracy: 0.3900\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0388 - accuracy: 0.6358 - val_loss: 0.0380 - val_accuracy: 0.5433\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0340 - accuracy: 0.6950 - val_loss: 0.0906 - val_accuracy: 0.8700\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0255 - accuracy: 0.6375 - val_loss: 0.0827 - val_accuracy: 0.5400\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0244 - accuracy: 0.6658 - val_loss: 0.0668 - val_accuracy: 0.5100\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0220 - accuracy: 0.6900 - val_loss: 0.0918 - val_accuracy: 0.6100\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0224 - accuracy: 0.6650 - val_loss: 0.0805 - val_accuracy: 0.6700\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0238 - accuracy: 0.6500 - val_loss: 0.1266 - val_accuracy: 0.5167\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0218 - accuracy: 0.6592 - val_loss: 0.0279 - val_accuracy: 0.8133\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0216 - accuracy: 0.6875 - val_loss: 0.0851 - val_accuracy: 0.4567\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0252 - accuracy: 0.6617 - val_loss: 0.1754 - val_accuracy: 0.5567\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0393 - accuracy: 0.6433 - val_loss: 0.1181 - val_accuracy: 0.5233\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0256 - accuracy: 0.6625 - val_loss: 0.0446 - val_accuracy: 0.7400\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0219 - accuracy: 0.6458 - val_loss: 0.0273 - val_accuracy: 0.6833\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0237 - accuracy: 0.6692 - val_loss: 0.0535 - val_accuracy: 0.5667\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0229 - accuracy: 0.6558 - val_loss: 0.1345 - val_accuracy: 0.5600\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0268 - accuracy: 0.6442 - val_loss: 0.0894 - val_accuracy: 0.8067\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0239 - accuracy: 0.7058 - val_loss: 0.0474 - val_accuracy: 0.8467\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0206 - accuracy: 0.6425 - val_loss: 0.0746 - val_accuracy: 0.6367\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0234 - accuracy: 0.6733 - val_loss: 0.0771 - val_accuracy: 0.6600\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0254 - accuracy: 0.6525 - val_loss: 0.1450 - val_accuracy: 0.5000\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0220 - accuracy: 0.6492 - val_loss: 0.0690 - val_accuracy: 0.6167\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0220 - accuracy: 0.6433 - val_loss: 0.0299 - val_accuracy: 0.5467\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0187 - accuracy: 0.6483 - val_loss: 0.0495 - val_accuracy: 0.6400\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0207 - accuracy: 0.6525 - val_loss: 0.0338 - val_accuracy: 0.6733\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0219 - accuracy: 0.6725 - val_loss: 0.0940 - val_accuracy: 0.4833\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0224 - accuracy: 0.6783 - val_loss: 0.0263 - val_accuracy: 0.9033\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0214 - accuracy: 0.6450 - val_loss: 0.0662 - val_accuracy: 0.7933\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0241 - accuracy: 0.6483 - val_loss: 0.0321 - val_accuracy: 0.8500\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0220 - accuracy: 0.6317 - val_loss: 0.0710 - val_accuracy: 0.7300\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0207 - accuracy: 0.6567 - val_loss: 0.0715 - val_accuracy: 0.5000\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0183 - accuracy: 0.6758 - val_loss: 0.0276 - val_accuracy: 0.6467\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0183 - accuracy: 0.6308 - val_loss: 0.0636 - val_accuracy: 0.8833\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0212 - accuracy: 0.6650 - val_loss: 0.1139 - val_accuracy: 0.6267\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0221 - accuracy: 0.6550 - val_loss: 0.0827 - val_accuracy: 0.5900\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0229 - accuracy: 0.6642 - val_loss: 0.0522 - val_accuracy: 0.8233\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0236 - accuracy: 0.6642 - val_loss: 0.0872 - val_accuracy: 0.5067\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0247 - accuracy: 0.6683 - val_loss: 0.0316 - val_accuracy: 0.5500\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0191 - accuracy: 0.6483 - val_loss: 0.0527 - val_accuracy: 0.9067\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0247 - accuracy: 0.6375 - val_loss: 0.1201 - val_accuracy: 0.4933\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0251 - accuracy: 0.6725 - val_loss: 0.0520 - val_accuracy: 0.8000\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0236 - accuracy: 0.6550 - val_loss: 0.0581 - val_accuracy: 0.5500\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0190 - accuracy: 0.6683 - val_loss: 0.0424 - val_accuracy: 0.6300\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0200 - accuracy: 0.6667 - val_loss: 0.0431 - val_accuracy: 0.5867\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0250 - accuracy: 0.6225 - val_loss: 0.0566 - val_accuracy: 0.6233\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0242 - accuracy: 0.6675 - val_loss: 0.1004 - val_accuracy: 0.5233\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0288 - accuracy: 0.6658 - val_loss: 0.0974 - val_accuracy: 0.5567\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0288 - accuracy: 0.6483 - val_loss: 0.0728 - val_accuracy: 0.5800\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0239 - accuracy: 0.6758 - val_loss: 0.1344 - val_accuracy: 0.5900\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0231 - accuracy: 0.6292 - val_loss: 0.0631 - val_accuracy: 0.6633\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0262 - accuracy: 0.6642 - val_loss: 0.0682 - val_accuracy: 0.5633\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0192 - accuracy: 0.6158 - val_loss: 0.0706 - val_accuracy: 0.7800\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0247 - accuracy: 0.6775 - val_loss: 0.0370 - val_accuracy: 0.5367\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0222 - accuracy: 0.6492 - val_loss: 0.0599 - val_accuracy: 0.4833\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0193 - accuracy: 0.6350 - val_loss: 0.0237 - val_accuracy: 0.8267\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0229 - accuracy: 0.6642 - val_loss: 0.0510 - val_accuracy: 0.6933\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0213 - accuracy: 0.6467 - val_loss: 0.1023 - val_accuracy: 0.6867\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0246 - accuracy: 0.6817 - val_loss: 0.0756 - val_accuracy: 0.8300\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0214 - accuracy: 0.6567 - val_loss: 0.0995 - val_accuracy: 0.5733\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0239 - accuracy: 0.6450 - val_loss: 0.0598 - val_accuracy: 0.8867\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0198 - accuracy: 0.6633 - val_loss: 0.0374 - val_accuracy: 0.5767\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0207 - accuracy: 0.6817 - val_loss: 0.1002 - val_accuracy: 0.5733\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0226 - accuracy: 0.6358 - val_loss: 0.0718 - val_accuracy: 0.8767\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0211 - accuracy: 0.6800 - val_loss: 0.0135 - val_accuracy: 0.7000\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0198 - accuracy: 0.6533 - val_loss: 0.0604 - val_accuracy: 0.6600\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0179 - accuracy: 0.6450 - val_loss: 0.0418 - val_accuracy: 0.6533\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0185 - accuracy: 0.6467 - val_loss: 0.1189 - val_accuracy: 0.6467\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0233 - accuracy: 0.6442 - val_loss: 0.0634 - val_accuracy: 0.5667\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0201 - accuracy: 0.6625 - val_loss: 0.0654 - val_accuracy: 0.8100\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0169 - accuracy: 0.6400 - val_loss: 0.0511 - val_accuracy: 0.7000\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0155 - accuracy: 0.6758 - val_loss: 0.0321 - val_accuracy: 0.5600\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0148 - accuracy: 0.6517 - val_loss: 0.0336 - val_accuracy: 0.5433\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0265 - accuracy: 0.6675 - val_loss: 0.0513 - val_accuracy: 0.8700\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0290 - accuracy: 0.6825 - val_loss: 0.2416 - val_accuracy: 0.3633\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0249 - accuracy: 0.6875 - val_loss: 0.0530 - val_accuracy: 0.4867\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0233 - accuracy: 0.6458 - val_loss: 0.1168 - val_accuracy: 0.8100\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0233 - accuracy: 0.6633 - val_loss: 0.0727 - val_accuracy: 0.5933\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0273 - accuracy: 0.6408 - val_loss: 0.0604 - val_accuracy: 0.6967\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0244 - accuracy: 0.6633 - val_loss: 0.0482 - val_accuracy: 0.7667\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0251 - accuracy: 0.6650 - val_loss: 0.0399 - val_accuracy: 0.6133\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0231 - accuracy: 0.6492 - val_loss: 0.0445 - val_accuracy: 0.6833\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0219 - accuracy: 0.6658 - val_loss: 0.0505 - val_accuracy: 0.6533\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0295 - accuracy: 0.6892 - val_loss: 0.0871 - val_accuracy: 0.5867\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0250 - accuracy: 0.6492 - val_loss: 0.0547 - val_accuracy: 0.6767\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6500 - val_loss: 0.0660 - val_accuracy: 0.5367\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0260 - accuracy: 0.6600 - val_loss: 0.0551 - val_accuracy: 0.6200\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0254 - accuracy: 0.6233 - val_loss: 0.0904 - val_accuracy: 0.5833\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0205 - accuracy: 0.6392 - val_loss: 0.0494 - val_accuracy: 0.4567\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0230 - accuracy: 0.6667 - val_loss: 0.0679 - val_accuracy: 0.5567\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0228 - accuracy: 0.6250 - val_loss: 0.0590 - val_accuracy: 0.6267\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0168 - accuracy: 0.6667 - val_loss: 0.0264 - val_accuracy: 0.5633\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0163 - accuracy: 0.6358 - val_loss: 0.0187 - val_accuracy: 0.8200\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0181 - accuracy: 0.6917 - val_loss: 0.1153 - val_accuracy: 0.4767\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0212 - accuracy: 0.6233 - val_loss: 0.0198 - val_accuracy: 0.7733\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0226 - accuracy: 0.6625 - val_loss: 0.0911 - val_accuracy: 0.5800\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0187 - accuracy: 0.6233 - val_loss: 0.0589 - val_accuracy: 0.6267\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0166 - accuracy: 0.6917 - val_loss: 0.0441 - val_accuracy: 0.5133\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0206 - accuracy: 0.6542 - val_loss: 0.0608 - val_accuracy: 0.4633\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0172 - accuracy: 0.6758 - val_loss: 0.0218 - val_accuracy: 0.7967\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0184 - accuracy: 0.6575 - val_loss: 0.0550 - val_accuracy: 0.5333\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0186 - accuracy: 0.6808 - val_loss: 0.0247 - val_accuracy: 0.6400\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0180 - accuracy: 0.6483 - val_loss: 0.0306 - val_accuracy: 0.7800\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0196 - accuracy: 0.6558 - val_loss: 0.0449 - val_accuracy: 0.5333\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0158 - accuracy: 0.6600 - val_loss: 0.0189 - val_accuracy: 0.6167\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0153 - accuracy: 0.6592 - val_loss: 0.0694 - val_accuracy: 0.6000\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0182 - accuracy: 0.6500 - val_loss: 0.0632 - val_accuracy: 0.8833\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0159 - accuracy: 0.6775 - val_loss: 0.0391 - val_accuracy: 0.8400\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0161 - accuracy: 0.6617 - val_loss: 0.0490 - val_accuracy: 0.5433\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0224 - accuracy: 0.6467 - val_loss: 0.0208 - val_accuracy: 0.8100\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0176 - accuracy: 0.6558 - val_loss: 0.0499 - val_accuracy: 0.5433\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0252 - accuracy: 0.6742 - val_loss: 0.0892 - val_accuracy: 0.5133\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0255 - accuracy: 0.6383 - val_loss: 0.0623 - val_accuracy: 0.8467\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6858 - val_loss: 0.1136 - val_accuracy: 0.5267\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0199 - accuracy: 0.6500 - val_loss: 0.0843 - val_accuracy: 0.6667\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0191 - accuracy: 0.6433 - val_loss: 0.0435 - val_accuracy: 0.5700\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0217 - accuracy: 0.6650 - val_loss: 0.0655 - val_accuracy: 0.8167\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0259 - accuracy: 0.6592 - val_loss: 0.0305 - val_accuracy: 0.6833\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0204 - accuracy: 0.6567 - val_loss: 0.0567 - val_accuracy: 0.6067\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0216 - accuracy: 0.6483 - val_loss: 0.0404 - val_accuracy: 0.7300\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0189 - accuracy: 0.6792 - val_loss: 0.0573 - val_accuracy: 0.6067\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0223 - accuracy: 0.6450 - val_loss: 0.0278 - val_accuracy: 0.6567\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0222 - accuracy: 0.6783 - val_loss: 0.0484 - val_accuracy: 0.6467\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0197 - accuracy: 0.6492 - val_loss: 0.0216 - val_accuracy: 0.7667\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0149 - accuracy: 0.6475 - val_loss: 0.0362 - val_accuracy: 0.6233\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0205 - accuracy: 0.6808 - val_loss: 0.0598 - val_accuracy: 0.5467\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0219 - accuracy: 0.6533 - val_loss: 0.0495 - val_accuracy: 0.5767\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0218 - accuracy: 0.6417 - val_loss: 0.0248 - val_accuracy: 0.6400\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0169 - accuracy: 0.6592 - val_loss: 0.0576 - val_accuracy: 0.7833\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0150 - accuracy: 0.6792 - val_loss: 0.0491 - val_accuracy: 0.6433\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0225 - accuracy: 0.6300 - val_loss: 0.0913 - val_accuracy: 0.5933\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0235 - accuracy: 0.6908 - val_loss: 0.0709 - val_accuracy: 0.6067\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0190 - accuracy: 0.6425 - val_loss: 0.0391 - val_accuracy: 0.4933\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0180 - accuracy: 0.6725 - val_loss: 0.0281 - val_accuracy: 0.6433\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0154 - accuracy: 0.6442 - val_loss: 0.0329 - val_accuracy: 0.5800\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0190 - accuracy: 0.6675 - val_loss: 0.0433 - val_accuracy: 0.5667\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0180 - accuracy: 0.6392 - val_loss: 0.0384 - val_accuracy: 0.5700\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0147 - accuracy: 0.6600 - val_loss: 0.0441 - val_accuracy: 0.8800\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0146 - accuracy: 0.6508 - val_loss: 0.0171 - val_accuracy: 0.5500\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0148 - accuracy: 0.6767 - val_loss: 0.0278 - val_accuracy: 0.9267\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0123 - accuracy: 0.6475 - val_loss: 0.0181 - val_accuracy: 0.5733\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0161 - accuracy: 0.6567 - val_loss: 0.0523 - val_accuracy: 0.4867\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0172 - accuracy: 0.6583 - val_loss: 0.0383 - val_accuracy: 0.6500\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0159 - accuracy: 0.6433 - val_loss: 0.0533 - val_accuracy: 0.8000\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0229 - accuracy: 0.6592 - val_loss: 0.0875 - val_accuracy: 0.5200\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0236 - accuracy: 0.6142 - val_loss: 0.1067 - val_accuracy: 0.6633\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0241 - accuracy: 0.6475 - val_loss: 0.0558 - val_accuracy: 0.9267\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0194 - accuracy: 0.6508 - val_loss: 0.0739 - val_accuracy: 0.5567\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0214 - accuracy: 0.6633 - val_loss: 0.0801 - val_accuracy: 0.4933\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0242 - accuracy: 0.6533 - val_loss: 0.1085 - val_accuracy: 0.6333\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0244 - accuracy: 0.6483 - val_loss: 0.0619 - val_accuracy: 0.6233\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0190 - accuracy: 0.6808 - val_loss: 0.1001 - val_accuracy: 0.5300\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0202 - accuracy: 0.6425 - val_loss: 0.0765 - val_accuracy: 0.6633\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0196 - accuracy: 0.6433 - val_loss: 0.0690 - val_accuracy: 0.6100\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0197 - accuracy: 0.6600 - val_loss: 0.0247 - val_accuracy: 0.5967\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0227 - accuracy: 0.6892 - val_loss: 0.0737 - val_accuracy: 0.7633\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0189 - accuracy: 0.6617 - val_loss: 0.0658 - val_accuracy: 0.5333\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0184 - accuracy: 0.6308 - val_loss: 0.0520 - val_accuracy: 0.8900\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0190 - accuracy: 0.6733 - val_loss: 0.0845 - val_accuracy: 0.5067\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0184 - accuracy: 0.6200 - val_loss: 0.0398 - val_accuracy: 0.7433\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0198 - accuracy: 0.6833 - val_loss: 0.0443 - val_accuracy: 0.5967\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0142 - accuracy: 0.6800 - val_loss: 0.0376 - val_accuracy: 0.4833\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0164 - accuracy: 0.6367 - val_loss: 0.0572 - val_accuracy: 0.7667\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0198 - accuracy: 0.6600 - val_loss: 0.0362 - val_accuracy: 0.5367\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0205 - accuracy: 0.6442 - val_loss: 0.0451 - val_accuracy: 0.7133\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0168 - accuracy: 0.6425 - val_loss: 0.0563 - val_accuracy: 0.6867\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0199 - accuracy: 0.6725 - val_loss: 0.0240 - val_accuracy: 0.8767\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0199 - accuracy: 0.6517 - val_loss: 0.0601 - val_accuracy: 0.4633\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0171 - accuracy: 0.6600 - val_loss: 0.0930 - val_accuracy: 0.5267\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0258 - accuracy: 0.6808 - val_loss: 0.0478 - val_accuracy: 0.8300\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0180 - accuracy: 0.6567 - val_loss: 0.0419 - val_accuracy: 0.6100\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0165 - accuracy: 0.6600 - val_loss: 0.0355 - val_accuracy: 0.5433\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0240 - accuracy: 0.6250 - val_loss: 0.1019 - val_accuracy: 0.9133\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.0233 - accuracy: 0.6792 - val_loss: 0.0656 - val_accuracy: 0.5933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qlPZlqiVnsUW",
        "outputId": "1edd5255-5109-4ded-bc80-25724f19001a"
      },
      "source": [
        "plt.plot(history2.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95kgLxG6hUpA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "aeeee7de-b835-4090-da70-a276d6851007"
      },
      "source": [
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik9wN-znteQh",
        "outputId": "80fbfece-b3b9-4efe-de83-fa57c113cc96"
      },
      "source": [
        "model2_pred = model2.predict(tf.reshape(defect_img[1],(-1,128,128,1)))\n",
        "model2_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03705702,  0.5355665 , -0.0272199 ,  1.884663  ,  0.91318005,\n",
              "         0.71477157,  0.7297575 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-mTlIf_thEz",
        "outputId": "027cde11-d18d-4c61-e960-641d33679bcf"
      },
      "source": [
        "np.round(model2_pred).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 2, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3_P4gLktkrU",
        "outputId": "388822ba-d152-40b9-fda4-1b6dd8f0e7ae"
      },
      "source": [
        "log_df.values[1]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 2, 1, 1, 1], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLoZGUmtmFl"
      },
      "source": [
        "# #교차검증\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# # 모델\n",
        "# CV_model = load_model('/content/DeepPCB-master/PCBDatamodel.h5')\n",
        "\n",
        "# # 파라미터는 (모델, Traingdata의 feature, Trainingdata의 target, 폴드수) 이다.\n",
        "# results = cross_val_score(CV_model, defect_img,boxarr ,cv=5)\n",
        "\n",
        "# # Trainingdata에 대한 성능을 나타낸다.\n",
        "# print('교차 검증별 정확도:',np.round(results, 3))\n",
        "# print('평균 검증 정확도:', np.round(np.mean(results), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTyTc9P7lOOx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}